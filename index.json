[{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/avance/ingress/","title":"Ingress","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Activer le contrôleur d\u0026rsquo;entrée Si vous utilisez minikube, vous devez activer le contrôleur NGNIX Ingress.\nminikube addons enable ingress\rAttendez une minute ou deux et vérifiez qu\u0026rsquo;il a été déployé correctement :\nkubectl get pods -n ingress-nginx\ringress-nginx-admission-create-lqfh2 0/1 Completed 0 6m28s\ringress-nginx-admission-patch-z2lzj 0/1 Completed 2 6m28s\ringress-nginx-controller-69ccf5d9d8-95xgp 1/1 Running 0 6m28s\rDéployer l\u0026rsquo;application cat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: quarkus-demo-deployment\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: quarkus-demo\rtemplate:\rmetadata:\rlabels:\rapp: quarkus-demo\renv: dev\rspec:\rcontainers:\r- name: quarkus-demo\rimage: quay.io/rhdevelopers/quarkus-demo:v1\rimagePullPolicy: Always\rports:\r- containerPort: 8080\rEOF\rExposez le service :\nkubectl expose deployment quarkus-demo-deployment --type=NodePort --port=8080\rkubectl get service quarkus-demo-deployment\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\rquarkus-demo-deployment NodePort 10.105.106.66 \u0026lt;none\u0026gt; 8080:30408/TCP 11s\rIP=$(minikube ip)\rPORT=$(kubectl get service/quarkus-demo-deployment -o jsonpath=\u0026quot;{.spec.ports[*].nodePort}\u0026quot;)\rRéaliser une requete sur le service :\ncurl $IP:$PORT\rConfiguration l\u0026rsquo;Ingress Une ressource d\u0026rsquo;entrée est définie comme suit :\nvim apps/kubefiles/demo-ingress.yaml\rapiVersion: networking.k8s.io/v1\rkind: Ingress\rmetadata:\rname: example-ingress\rannotations:\rnginx.ingress.kubernetes.io/rewrite-target: /$1\rspec:\rrules:\r- host: kube-team.info\rhttp:\rpaths:\r- path: /\rpathType: Prefix\rbackend:\rservice:\rname: quarkus-demo-deployment\rport:\rnumber: 8080\rkubectl apply -f apps/kubefiles/demo-ingress.yaml\rObtenir les informations de la ressource Ingress :\nkubectl get ingress\rNAME CLASS HOSTS ADDRESS PORTS AGE\rexample-ingress \u0026lt;none\u0026gt; kube-team.info 192.168.99.115 80 68s\rVous devez attendre que le champ d\u0026rsquo;adresse soit défini. Cela peut prendre quelques minutes.\nModifiez le fichier /etc/hosts pour faire pointer le nom d\u0026rsquo;hôte vers l\u0026rsquo;adresse Ingress.\nminikube ip\r10.240.145.124\rsudo vim /etc/hosts\r10.240.145.124 kube-team.info\rcurl kube-devnation.info\rSi vous avez un proxy :\ncurl --noproxy kube-devnation.info kube-devnation.info\rSupersonic Subatomic Java with Quarkus quarkus-demo-deployment-8cf45f5c8-qmzwl:1\rDeuxième déploiement Déployer une deuxième version du service :\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: mynode-deployment\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: mynode\rtemplate:\rmetadata:\rlabels:\rapp: mynode\rspec:\rcontainers:\r- name: mynode\rimage: quay.io/rhdevelopers/mynode:v1\rports:\r- containerPort: 8000\rEOF\rkubectl expose deployment mynode-deployment --type=NodePort --port=8000\rMise à jour de l\u0026rsquo;Ingress Ensuite, vous devez mettre à jour la ressource Ingress avec le nouveau chemin :\nvim apps/kubefiles/demo-ingress-2.yaml\rapiVersion: networking.k8s.io/v1beta1\rkind: Ingress\rmetadata:\rname: example-ingress\rannotations:\rnginx.ingress.kubernetes.io/rewrite-target: /$1\rspec:\rrules:\r- host: kube-team.info\rhttp:\rpaths:\r- path: /\rbackend:\rserviceName: quarkus-demo-deployment\rservicePort: 8080\r- path: /v2\rbackend:\rserviceName: mynode-deployment\rservicePort: 8000\rkubectl apply -f apps/kubefiles/demo-ingress-2.yaml\rTester :\ncurl kube-team.info\rSupersonic Subatomic Java with Quarkus quarkus-demo-deployment-8cf45f5c8-qmzwl:2\rcurl kube-team.info/v2\rNode Bonjour on mynode-deployment-77c7bf857d-5nfl4 0\rSupprimer les ressources\nkubectl delete deployment mynode-deployment\rkubectl delete service mynode-deployment\rkubectl delete deployment quarkus-demo-deployment\rkubectl delete service quarkus-demo-deployment\rkubectl delete -f apps/kubefiles/demo-ingress-2.yaml\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/d%C3%A9butant/kubectl/","title":"Kubectl","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Parlez à votre Cluster echo $KUBECONFIG\rkubectl config view\rAffiche les paramètres fusionnés de kubeconfig\nVue du noeud kubectl get nodes\rkubectl get nodes --show-labels\rkubectl get namespaces\rAffiche tous les noeuds, les labels définit et les espaces de noms.\nVoir les Pods prêts à l\u0026rsquo;emploi Votre fournisseur de Kubernetes comprend probablement de nombreuses espaces de noms prêtes à l\u0026rsquo;emploi :\nkubectl get pods --all-namespaces\rkubectl get pods --all-namespaces --show-labels\rkubectl get pods --all-namespaces -o wide\rAffiche tous les espaces de noms, les labels définit et les sorties. Les espaces de noms sont destinés à être utilisés dans des environnements avec de nombreux utilisateurs répartis sur plusieurs équipes ou projets. Les espaces de noms sont un moyen de diviser les ressources du cluster entre plusieurs utilisateurs\nDéployer quelque chose Créer un espace de nommage et déployer quelque chose :\nkubectl create namespace mystuff\rkubectl config set-context --current --namespace=mystuff\rkubectl create deployment myapp --image=quay.io/rhdevelopers/quarkus-demo:v1\rLa commande \u0026ldquo;kubectl config set-context\u0026rdquo; permet une bascule rapide entre les namespaces du cluster kubernetes.\nTout en surveillant les événements terminal 2\nwatch kubectl get events --sort-by=.metadata.creationTimestamp\rLAST SEEN TYPE REASON OBJECT MESSAGE\r\u0026lt;unknown\u0026gt; Normal Scheduled pod/myapp-5dcbf46dfc-ghrk4 Successfully assigned mystuff/myapp-5dcbf46dfc-ghrk4 to g\rcp-5xldg-w-a-5ptpn.us-central1-a.c.ocp42project.internal\r29s Normal SuccessfulCreate replicaset/myapp-5dcbf46dfc Created pod: myapp-5dcbf46dfc-ghrk4\r29s Normal ScalingReplicaSet deployment/myapp Scaled up replica set myapp-5dcbf46dfc to 1\r21s Normal Pulling pod/myapp-5dcbf46dfc-ghrk4 Pulling image \u0026quot;quay.io/burrsutter/quarkus-demo:1.0.0\u0026quot;\r15s Normal Pulled pod/myapp-5dcbf46dfc-ghrk4 Successfully pulled image \u0026quot;quay.io/burrsutter/quarkus-dem\ro:1.0.0\u0026quot;\r15s Normal Created pod/myapp-5dcbf46dfc-ghrk4 Created container quarkus-demo\r15s Normal Started pod/myapp-5dcbf46dfc-ghrk4 Started container quarkus-demo\rLa commande \u0026ldquo;watch\u0026rdquo; permet d\u0026rsquo;initer une écoute en temps réel des modifications d\u0026rsquo;un objet.\nObjets créés Déploiements\nkubectl get deployments\rNAME READY UP-TO-DATE AVAILABLE AGE\rmyapp 1/1 1 1 95s\rLa sortie observer permet de connaitre l\u0026rsquo;état du déploiment d\u0026rsquo;un ou plusieurs pods. Le déploiement fournit des mises à jour déclaratives pour Pods et ReplicaSets. Il permet de décrire l\u0026rsquo;état désiré et le controlleur du déploiement change l\u0026rsquo;état réel à l\u0026rsquo;état souhaité.\nReplicasets\nkubectl get replicasets\rNAME DESIRED CURRENT READY AGE\rmyapp-5dcbf46dfc 1 1 1 2m1s\rLa sortie observer permet de connaitre l\u0026rsquo;état d\u0026rsquo;un ensemble stable de Pods à un moment donné. Cet objet est souvent utilisé pour garantir la disponibilité d\u0026rsquo;un certain nombre identique de Pods.\nPods\nkubectl get pods --show-labels\rNAME READY STATUS RESTARTS AGE LABELS\rmyapp-5dcbf46dfc-ghrk4 1/1 Running 0 2m18s app=myapp,pod-template-hash=5dcbf46dfc\rLa sortie observer permet de connaitre l\u0026rsquo;état du pod. Les Pods sont les plus petites unités informatiques déployables qui peuvent être créées et gérées dans Kubernetes.\nUn pod (terme anglo-saxon décrivant un groupe de baleines ou une gousse de pois) est un groupe d\u0026rsquo;un ou plusieurs conteneurs (comme des conteneurs Docker), ayant du stockage/réseau partagé, et une spécification sur la manière d\u0026rsquo;exécuter ces conteneurs. Les éléments d\u0026rsquo;un pod sont toujours co-localisés et co-ordonnancés, et s\u0026rsquo;exécutent dans un contexte partagé. Un pod modélise un \u0026ldquo;hôte logique\u0026rdquo; spécifique à une application - il contient un ou plusieurs conteneurs applicatifs qui sont étroitement liés — dans un monde pré-conteneurs, être exécuté sur la même machine physique ou virtuelle signifierait être exécuté sur le même hôte logique.\nLogs\nkubectl logs -l app=myapp\r2020-03-22 14:41:30,497 INFO [io.quarkus] (main) Quarkus 0.22.0 started in 0.021s. Listening on: http://0.0.0.0:8080\r2020-03-22 14:41:30,497 INFO [io.quarkus] (main) Installed features: [cdi, resteasy]\rExposer un service kubectl expose deployment myapp --port=8080 --type=LoadBalancer\rterminal 2\nwatch kubectl get services\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\rmyapp LoadBalancer 172.30.103.41 \u0026lt;pending\u0026gt; 8080:31974/TCP 4s\rKubernetes ServiceTypesvous permet de spécifier le type de service que vous souhaitez. La valeur par défaut est ClusterIP.\nType les valeurs et leurs comportements sont:\n  ClusterIP: Expose le service sur une IP interne au cluster. Le choix de cette valeur rend le service uniquement accessible à partir du cluster. C\u0026rsquo;est la valeur par défaut ServiceType.\n  NodePort: Expose le service sur l\u0026rsquo;IP de chaque nœud à un port statique (le NodePort). Un ClusterIPservice, vers lequel le NodePortservice est acheminé, est automatiquement créé. Vous pourrez contacter le NodePortService, depuis l\u0026rsquo;extérieur du cluster, en faisant la demande :.\n  LoadBalancer: Expose le service en externe à l\u0026rsquo;aide de l\u0026rsquo;équilibreur de charge d\u0026rsquo;un fournisseur de cloud. NodePortet les ClusterIPservices, vers lesquels les itinéraires de l\u0026rsquo;équilibreur de charge externe, sont automatiquement créés.\n  ExternalName: Mappe le service au contenu du externalNamechamp (par exemple foo.bar.example.com), en renvoyant un CNAME enregistrement avec sa valeur. Aucun mandataire d\u0026rsquo;aucune sorte n\u0026rsquo;est mis en place.\n  Parler aux applications IP=$(minikube ip)\rPORT=$(kubectl get service/myapp -o jsonpath=\u0026quot;{.spec.ports[*].nodePort}\u0026quot;)\rBouclez le service :\ncurl $IP:$PORT\rScalez l\u0026rsquo;application\nterminal 2\nwatch kubectl get pods\rterminal 1\nIP=$(kubectl get service myapp -o jsonpath=\u0026quot;{.status.loadBalancer.ingress[0].ip}\u0026quot;)\rPORT=$(kubectl get service myapp -o jsonpath=\u0026quot;{.spec.ports[*].port}\u0026quot;)\rSondez le résultat :\nwhile true\rdo curl $IP:$PORT\rsleep .3\rdone\rRésultats du sondage :\nSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:289\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:290\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:291\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:292\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:293\rTerminal 3 Changer les répliques :\nkubectl scale deployment myapp --replicas=3\rNAME READY STATUS RESTARTS AGE\rmyapp-5dcbf46dfc-6sn2s 0/1 ContainerCreating 0 4s\rmyapp-5dcbf46dfc-ghrk4 1/1 Running 0 5m32s\rmyapp-5dcbf46dfc-z6hqw 0/1 ContainerCreating 0 4s\rCommencez une mise à jour continue en changeant l\u0026rsquo;image :\nkubectl set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/myboot:v1\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-6sn2s:188\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-z6hqw:169\rAloha from Spring Boot! 0 on myapp-58b97dbd95-vxd87\rAloha from Spring Boot! 1 on myapp-58b97dbd95-vxd87\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-6sn2s:189\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-z6hqw:170\rAloha from Spring Boot! 2 on myapp-58b97dbd95-vxd87\rkubectl set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/myboot:v2\rBonjour from Spring Boot! 2 on myapp-7d58855c6b-6c8gd\rBonjour from Spring Boot! 3 on myapp-7d58855c6b-6c8gd\rAloha from Spring Boot! 7 on myapp-58b97dbd95-mjlwx\rBonjour from Spring Boot! 4 on myapp-7d58855c6b-6c8gd\rAloha from Spring Boot! 8 on myapp-58b97dbd95-mjlwx\rBonjour from Spring Boot! 5 on myapp-7d58855c6b-6c8gd\rkubectl set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/quarkus-demo:v1\rBonjour from Spring Boot! 14 on myapp-7d58855c6b-dw67s\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:3\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:4\rBonjour from Spring Boot! 15 on myapp-7d58855c6b-dw67s\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:5\rBonjour from Spring Boot! 13 on myapp-7d58855c6b-72wp8\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:1\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:2\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:1\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:3\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:2\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:3\rSupersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:6\rNettoyage kubectl delete namespace mystuff\rkubectl config set-context --current --namespace=default"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/%C3%A9l%C3%A9mentaire/ressources-limites/","title":"Ressources et limites","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Assurez-vous que vous êtes dans le bon espace de noms :\nkubectl config set-context --current --namespace=myspace\rAssurez-vous que rien n\u0026rsquo;est en cours d\u0026rsquo;exécution dans votre espace de nom :\nkubectl get all\rNo resources found in myspace namespace.\rDéployez d\u0026rsquo;abord une application sans aucune Requête ni Limite :\nCréer un fichier de déploiement\nmkdir -p apps/kubefiles/\rvi apps/kubefiles/myboot-deployment.yml\rmyboot-deployment.yml\napiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot\rname: myboot\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot\rtemplate:\rmetadata:\rlabels:\rapp: myboot\rspec:\rcontainers:\r- name: myboot\rimage: quay.io/rhdevelopers/myboot:v2\rports:\r- containerPort: 8080\rDéployer la version 1 de l\u0026rsquo;applciation myboot\nkubectl apply -f apps/kubefiles/myboot-deployment.yml\rDécrivez le pod :\nPODNAME=$(kubectl get pod -l app=myboot -o name)\rkubectl describe $PODNAME\rIl n\u0026rsquo;y a pas de limites de ressources configurées pour le pod.\nName: myboot-66d7d57687-jzbzj\rNamespace: myspace\rPriority: 0\rNode: gcp-5xldg-w-b-rlp45.us-central1-b.c.ocp42project.internal/10.0.32.5\rStart Time: Sun, 29 Mar 2020 14:24:24 -0400\rLabels: app=myboot\rpod-template-hash=66d7d57687\rAnnotations: k8s.v1.cni.cncf.io/networks-status:\r[{\r\u0026quot;name\u0026quot;: \u0026quot;openshift-sdn\u0026quot;,\r\u0026quot;interface\u0026quot;: \u0026quot;eth0\u0026quot;,\r\u0026quot;ips\u0026quot;: [\r\u0026quot;10.130.2.23\u0026quot;\r],\r\u0026quot;dns\u0026quot;: {},\r\u0026quot;default-route\u0026quot;: [\r\u0026quot;10.130.2.1\u0026quot;\r]\r}]\ropenshift.io/scc: restricted\rStatus: Running\rIP: 10.130.2.23\rIPs:\rIP: 10.130.2.23\rControlled By: ReplicaSet/myboot-66d7d57687\rContainers:\rmyboot:\rContainer ID: cri-o://2edfb0a5a93f375516ee49d33df20bee40c14792b37ec1648dc5205244095a53\rImage: quay.io/burrsutter/myboot:v1\rImage ID: quay.io/burrsutter/myboot@sha256:cdf39f191f5d322ebe6c04cae218b0ad8f6dbbb8a81e81a88c0fbc6e3c05f860\rPort: 8080/TCP\rHost Port: 0/TCP\rState: Running\rStarted: Sun, 29 Mar 2020 14:24:32 -0400\rReady: True\rRestart Count: 0\rEnvironment: \u0026lt;none\u0026gt;\rMounts:\r/var/run/secrets/kubernetes.io/serviceaccount from default-token-vlzsl (ro)\rConditions:\rType Status\rInitialized True\rReady True\rContainersReady True\rPodScheduled True\rVolumes:\rdefault-token-vlzsl:\rType: Secret (a volume populated by a Secret)\rSecretName: default-token-vlzsl\rOptional: false\rQoS Class: BestEffort\rNode-Selectors: \u0026lt;none\u0026gt;\rTolerations: node.kubernetes.io/not-ready:NoExecute for 300s\rnode.kubernetes.io/unreachable:NoExecute for 300s\rEvents:\rType Reason Age From Message\r---- ------ ---- ---- -------\rNormal Scheduled \u0026lt;unknown\u0026gt; default-scheduler Successfully assigned myspace/myboot-66d7d57687-jzbzj to gcp-5xldg-w-b-rlp45.us-central1-b.c.ocp42project.internal\rNormal Pulled 12m kubelet, gcp-5xldg-w-b-rlp45.us-central1-b.c.ocp42project.internal Container image \u0026quot;quay.io/burrsutter/myboot:v1\u0026quot; already present on machine\rNormal Created 12m kubelet, gcp-5xldg-w-b-rlp45.us-central1-b.c.ocp42project.internal Created container myboot\rNormal Started 12m kubelet, gcp-5xldg-w-b-rlp45.us-central1-b.c.ocp42project.internal Started container myboot\rSupprimez ce déploiement :\nkubectl delete deployment myboot\rCréez un nouveau déploiement avec des demandes de ressources :\nCréer un fichier de déploiement\nvi apps/kubefiles/myboot-deployment-resources.yml\rmyboot-deployment-resources.yml\napiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot\rname: myboot\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot\rtemplate:\rmetadata:\rlabels:\rapp: myboot\rspec:\rcontainers:\r- name: myboot\rimage: quay.io/rhdevelopers/myboot:v1\rports:\r- containerPort: 8080\rresources:\rrequests:\rmemory: \u0026quot;300Mi\u0026quot;\rcpu: \u0026quot;10000m\u0026quot; # 10 cores\rkubectl apply -f apps/kubefiles/myboot-deployment-resources.yml\rEt vérifiez le statut du Pod :\nkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-7b7d754c86-kjwlr 0/1 Pending 0 19s\rSi vous voulez obtenir plus d\u0026rsquo;informations sur l\u0026rsquo;erreur :\nkubectl get events --sort-by=.metadata.creationTimestamp\r\u0026lt;unknown\u0026gt; Warning FailedScheduling pod/myboot-7b7d754c86-kjwlr 0/6 nodes are available: 6 Insufficient cpu.\r\u0026lt;unknown\u0026gt; Warning FailedScheduling pod/myboot-7b7d754c86-kjwlr 0/6 nodes are available: 6 Insufficient cpu.\rLes \u0026ldquo;demandes de ressources\u0026rdquo; de la spécification du pod exigent qu\u0026rsquo;au moins un nœud de travail ait N cœurs et X mémoires disponibles. Si aucun nœud de travail ne répond à ces exigences, vous recevez le message \u0026ldquo;PENDING\u0026rdquo; et les notations appropriées dans la liste des événements.\nVous pouvez également utiliser kubectl describe sur le pod pour trouver plus d\u0026rsquo;informations sur l\u0026rsquo;échec.\nPODNAME=$(kubectl get pod -l app=myboot -o name)\rkubectl describe $PODNAME\rSupprimez le déploiement :\nkubectl delete -f apps/kubefiles/myboot-deployment-resources.yml\rCréez un nouveau déploiement avec une demande de ressources plus raisonnable et une limite stricte :\nCréer un fichier de déploiement\nvi apps/kubefiles/myboot-deployment-resources-limits.yml\rmyboot-deployment-resources-limits.yml\napiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot\rname: myboot\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot\rtemplate:\rmetadata:\rlabels:\rapp: myboot\rspec:\rcontainers:\r- name: myboot\rimage: quay.io/rhdevelopers/myboot:v1\rports:\r- containerPort: 8080\rresources:\rrequests:\rmemory: \u0026quot;300Mi\u0026quot;\rcpu: \u0026quot;250m\u0026quot; # 1/4 core\r# NOTE: These are the same limits we tested our Docker Container with earlier\r# -m matches limits.memory and --cpus matches limits.cpu\rlimits:\rmemory: \u0026quot;400Mi\u0026quot;\rcpu: \u0026quot;1000m\u0026quot; # 1 core\rkubectl apply -f apps/kubefiles/myboot-deployment-resources-limits.yml\rDécrivez le Pod :\nPODNAME=$(kubectl get pod -l app=myboot -o name)\rkubectl describe $PODNAME\rDéployer le service :\nCréer un fichier pour votre service\nvi apps/kubefiles/myboot-service.yml\rmyboot-service.yml\napiVersion: v1\rkind: Service\rmetadata:\rname: myboot\rlabels:\rapp: myboot\rspec:\rports:\r- name: http\rport: 8080\rselector:\rapp: myboot\rtype: LoadBalancer\rkubectl apply -f apps/kubefiles/myboot-service.yml\rEt surveillez votre Pod:\nwatch kubectl get pods\rCréer les variables IP et Port\nIP=$(minikube ip)\rPORT=$(kubectl get service/myboot -o jsonpath=\u0026quot;{.spec.ports[*].nodePort}\u0026quot;)\rRéaliser une requete sur le sevrice\ncurl $IP:$PORT\rExécuter une boucle\nwhile true\rdo curl $IP:$PORT\rsleep .3\rdone\rDans une autre fenêtre de terminal, curl le point de terminaison /sysresources\ncurl $IP:$PORT/sysresources\rPODNAME=$(kubectl get pod -l app=myboot -o name)\rkubectl get $PODNAME -o json | jq \u0026quot;.spec.containers[0].resources\u0026quot;\r{\r\u0026quot;limits\u0026quot;: {\r\u0026quot;cpu\u0026quot;: \u0026quot;1\u0026quot;,\r\u0026quot;memory\u0026quot;: \u0026quot;400Mi\u0026quot;\r},\r\u0026quot;requests\u0026quot;: {\r\u0026quot;cpu\u0026quot;: \u0026quot;250m\u0026quot;,\r\u0026quot;memory\u0026quot;: \u0026quot;300Mi\u0026quot;\r}\r}\rPuis curl le point de terminaison /consume :\ncurl $IP:$PORT/consume\rcurl: (52) Empty reply from server\rEt vous devriez remarquer que votre boucle échoue également :\nAloha from Spring Boot! 1120 on myboot-d78fb6d58-69kl7\rcurl: (56) Recv failure: Connection reset by peer\rDécrivez le Pod pour voir l\u0026rsquo;erreur :\nPODNAME=$(kubectl get pod -l app=myboot -o name)\rkubectl describe $PODNAME\rEt cherchez la partie suivante :\n Last State: Terminated\rReason: OOMKilled\rExit Code: 137\rkubectl get $PODNAME -o json | jq \u0026quot;.status.containerStatuses[0].lastState.terminated\u0026quot;\r{\r\u0026quot;containerID\u0026quot;: \u0026quot;cri-o://7b9be70ce4b616d6083d528dee708cea879da967373dad0d396fb999bd3898d3\u0026quot;,\r\u0026quot;exitCode\u0026quot;: 137,\r\u0026quot;finishedAt\u0026quot;: \u0026quot;2020-03-29T19:14:56Z\u0026quot;,\r\u0026quot;reason\u0026quot;: \u0026quot;OOMKilled\u0026quot;,\r\u0026quot;startedAt\u0026quot;: \u0026quot;2020-03-29T18:50:15Z\u0026quot;\r}\rVous pourriez même voir la colonne STATUS avec watch kubectl get pods pour visualiser le OOMKilled :\nNAME READY STATUS RESTARTS AGE\rmyboot-d78fb6d58-69kl7 0/1 OOMKilled 1 30m\rEt vous remarquerez que la colonne RESTARTS s\u0026rsquo;incrémente à chaque plantage du pod Spring Boot.\n"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/intermediare/secret/","title":"Secret","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Déployer le service myboot :\nkubectl apply -f apps/kubefiles/myboot-deployment.yml\rDéployer le service myboot :\nkubectl apply -f apps/kubefiles/myboot-service.yml\rRegardez vos Pods:\nwatch kubectl get pods\rRegardez vos services:\nwatch kubectl get services\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\rmyapp LoadBalancer 172.30.103.41 \u0026lt;pending\u0026gt; 8080:31974/TCP 4s\rAttendez jusqu\u0026rsquo;à ce que vous voyez une IP externe assignée.\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\rmyapp LoadBalancer 172.30.103.41 34.71.122.153 8080:31974/TCP 44s\rCréer les variables IP et PORT :\nIP=$(minikube ip)\rPORT=$(kubectl get service/myboot -o jsonpath=\u0026quot;{.spec.ports[*].nodePort}\u0026quot;)\rRéaliser une requete du service :\ncurl $IP:$PORT\rL\u0026rsquo;exemple de ConfigMap présenté précédemment contenait une chaîne de connexion à une base de données (\u0026ldquo;user=MyUserName;password=*\u0026quot;). Les données sensibles comme les mots de passe peuvent être placées dans un autre récipient appelé Secret.\nCréer des secrets kubectl create secret generic mysecret --from-literal=user='MyUserName' --from-literal=password='mypassword'\rkubectl get secrets\rNAME TYPE DATA AGE\rbuilder-dockercfg-96ml5 kubernetes.io/dockercfg 1 3d6h\rbuilder-token-h5g82 kubernetes.io/service-account-token 4 3d6h\rbuilder-token-vqjqz kubernetes.io/service-account-token 4 3d6h\rdefault-dockercfg-bsnjr kubernetes.io/dockercfg 1 3d6h\rdefault-token-bl77s kubernetes.io/service-account-token 4 3d6h\rdefault-token-vlzsl kubernetes.io/service-account-token 4 3d6h\rdeployer-dockercfg-k6npn kubernetes.io/dockercfg 1 3d6h\rdeployer-token-4hb78 kubernetes.io/service-account-token 4 3d6h\rdeployer-token-vvh6r kubernetes.io/service-account-token 4 3d6h\rmysecret Opaque 2 5s\rL\u0026rsquo;utilisateur et le mot de passe ne sont pas immédiatement visibles :\nName: mysecret\rNamespace: myspace\rLabels: \u0026lt;none\u0026gt;\rAnnotations: \u0026lt;none\u0026gt;\rType: Opaque\rData\r====\rpassword: 10 bytes\ruser: 10 bytes\rapiVersion: v1\rdata:\rpassword: bXlwYXNzd29yZA==\ruser: TXlVc2VyTmFtZQ==\rkind: Secret\rmetadata:\rcreationTimestamp: \u0026quot;2020-03-31T20:19:26Z\u0026quot;\rname: mysecret\rnamespace: myspace\rresourceVersion: \u0026quot;4944690\u0026quot;\rselfLink: /api/v1/namespaces/myspace/secrets/mysecret\ruid: e8c5f12e-bd71-4d6b-8d8c-7af9ed6439f8\rtype: Opaque\rVous pouvez voir les secrets en courant :\necho 'bXlwYXNzd29yZA==' | base64 --decode\rmypassword\recho 'TXlVc2VyTmFtZQ==' | base64 --decode\rMyUserName\rOu les obtenir en utilisant kubectl :\nkubectl get secret mysecret -o jsonpath='{.data.password}' | base64 --decode\rLes secrets sont fournis au Pod via des montages de volumes :\n volumeMounts:\r- name: mysecretvolume\rmountPath: /mystuff/mysecretvolume\rNouveau déploiement avec le volume secret :\nvim apps/kubefiles/myboot-deployment-configuration-secret.yml\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot\rname: myboot\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot\rtemplate:\rmetadata:\rlabels:\rapp: myboot\rspec:\rcontainers:\r- name: myboot\rimage: quay.io/rhdevelopers/myboot:v1\rports:\r- containerPort: 8080\rvolumeMounts:\r- name: mysecretvolume #\u0026lt;.\u0026gt;\rmountPath: /mystuff/secretstuff\rreadOnly: true\rresources:\rrequests:\rmemory: \u0026quot;300Mi\u0026quot;\rcpu: \u0026quot;250m\u0026quot; # 1/4 core\rlimits:\rmemory: \u0026quot;400Mi\u0026quot;\rcpu: \u0026quot;1000m\u0026quot; # 1 core\rvolumes:\r- name: mysecretvolume #\u0026lt;.\u0026gt;\rsecret:\rsecretName: mysecret\rkubectl replace -f apps/kubefiles/myboot-deployment-configuration-secret.yml\rExec dans le Pod nouvellement créé :\nPODNAME=$(kubectl get pod -l app=myboot -o name)\rkubectl exec $PODNAME -- cat /mystuff/secretstuff/password\rRésultat\nmypassword\rVous pourriez fournir l\u0026rsquo;emplacement de /mystuff/mysecretvolume au pod via une variable d\u0026rsquo;environnement afin que l\u0026rsquo;application sache où chercher.\nSupprimer vos ressources\nkubectl delete deployment myboot\rkubectl delete service myboot\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/%C3%A9l%C3%A9mentaire/mise-a-jour/","title":"Mise à jour permanentes","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Assurez-vous que vous êtes dans le bon espace de noms :\nkubectl config set-context --current --namespace=myspace\rDéployez l\u0026rsquo;application Spring Boot si nécessaire :\nkubectl apply -f apps/kubefiles/myboot-deployment-resources-limits.yml\rkubectl apply -f apps/kubefiles/myboot-service.yml\rTerminal 1 : regardez les Pods.\nwatch kubectl get pods\rTerminal 2: curl loop the service.\nIP=$(minikube ip -p devnation)\rPORT=$(kubectl get service/myboot -o jsonpath=\u0026quot;{.spec.ports[*].nodePort}\u0026quot;)\rRéaliser une requete sur le service :\ncurl $IP:$PORT\rEt lancez le script de la boucle :\nwhile true\rdo curl $IP:$PORT\rsleep .3\rdone\rTerminal 3 : Exécuter des commandes.\nDécrire le déploiement :\nkubectl describe deployment myboot\r.\r.\r.\rReplicas: 1 desired | 1 updated | 1 total | 1 available | 0 unavailable\rStrategyType: RollingUpdate\rMinReadySeconds: 0\rRollingUpdateStrategy: 25% max unavailable, 25% max surge\r.\r.\r.\rLes options StrategyType comprennent RollingUpdate et Recreate :\nModifier les repliquas :\nkubectl edit deployment myboot\rRecherchez les \u0026ldquo;réplicas\u0026rdquo; :\nspec:\rprogressDeadlineSeconds: 600\rreplicas: 1\rrevisionHistoryLimit: 10\rselector:\rmatchLabels:\rapp: myboot\rEt mettez à jour à \u0026ldquo;2\u0026rdquo; :\nspec:\rprogressDeadlineSeconds: 600\rreplicas: 2\rrevisionHistoryLimit: 10\rselector:\rmatchLabels:\rapp: myboot\rEnregistrez et un nouveau pod prendra vie :\nkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-d78fb6d58-2fqml 1/1 Running 0 25s\rmyboot-d78fb6d58-ljkjp 1/1 Running 0 3m\rModifiez l\u0026rsquo;image associée au déploiement :\nkubectl edit deployment myboot\rTrouvez l\u0026rsquo;attribut de l\u0026rsquo;image :\n spec:\rcontainers:\r- image: quay.io/rhdevelopers/myboot:v1\rimagePullPolicy: IfNotPresent\rname: myboot\ret changez l\u0026rsquo;image myboot:v2 :\n spec:\rcontainers:\r- image: quay.io/rhdevelopers/myboot:v2\rimagePullPolicy: IfNotPresent\rname: myboot\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-7fbc4b97df-4ntmk 1/1 Running 0 9s\rmyboot-7fbc4b97df-qtkzj 0/1 ContainerCreating 0 0s\rmyboot-d78fb6d58-2fqml 1/1 Running 0 3m29s\rmyboot-d78fb6d58-ljkjp 1/1 Terminating 0 8m\rEt la sortie du terminal 2 :\nAloha from Spring Boot! 211 on myboot-d78fb6d58-2fqml\rAloha from Spring Boot! 212 on myboot-d78fb6d58-2fqml\rBonjour from Spring Boot! 0 on myboot-7fbc4b97df-4ntmk\rBonjour from Spring Boot! 1 on myboot-7fbc4b97df-4ntmk\rVérifiez l\u0026rsquo;état du déploiement :\nkubectl rollout status deployment myboot\rdeployment \u0026quot;myboot\u0026quot; successfully rolled out\rRemarquez qu\u0026rsquo;il y a un nouveau RS :\nkubectl get rs\rNAME DESIRED CURRENT READY AGE\rmyboot-7fbc4b97df 2 2 2 116s\rmyboot-d78fb6d58 0 0 0 10m\rDécrire le déploiement :\nkubectl describe deployment myboot\rEt consultez la section \u0026ldquo;Événements\u0026rdquo; :\n...\rEvents:\rType Reason Age From Message\r---- ------ ---- ---- -------\rNormal ScalingReplicaSet 16m deployment-controller Scaled up replica set myboot-d78fb6d58 to 1\rNormal ScalingReplicaSet 6m15s deployment-controller Scaled up replica set myboot-d78fb6d58 to 2\rNormal ScalingReplicaSet 2m55s deployment-controller Scaled up replica set myboot-7fbc4b97df to 1\rNormal ScalingReplicaSet 2m46s deployment-controller Scaled down replica set myboot-d78fb6d58 to 1\rNormal ScalingReplicaSet 2m46s deployment-controller Scaled up replica set myboot-7fbc4b97df to 2\rNormal ScalingReplicaSet 2m37s deployment-controller Scaled down replica set myboot-d78fb6d58 to 0\rRetour à la version 1 :\nkubectl set image deployment myboot myboot=quay.io/rhdevelopers/myboot:v1\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/intermediare/operator/","title":"Operator","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Les ressources personnalisées étendent l\u0026rsquo;API\nLes contrôleurs personnalisés fournissent la fonctionnalité - qui maintient continuellement l\u0026rsquo;état souhaité - pour surveiller son état et rapprocher la ressource de la configuration.\nDocs Custom Resources\nDocs Custom Resource Definition\nDéfinitions de ressources personnalisées (CRD) dans la version 1.7\nCRDs kubectl get crds --all-namespaces\rkubectl api-resources\rExemple CRD\napiVersion: apiextensions.k8s.io/v1beta1\rkind: CustomResourceDefinition\rmetadata:\rname: pizzas.mykubernetes.acme.org\rlabels:\rapp: pizzamaker\rmylabel: stuff\rspec:\rgroup: mykubernetes.acme.org\rscope: Namespaced\rversion: v1beta2\rnames:\rkind: Pizza\rlistKind: PizzaList\rplural: pizzas\rsingular: pizza\rshortNames:\r- pz\rAjoutez des Pizzas\nmkdir -p apps/pizzas/\rvim pizza-crd.yaml\rpizza-crd.yaml\napiVersion: apiextensions.k8s.io/v1\rkind: CustomResourceDefinition\rmetadata:\rname: pizzas.mykubernetes.acme.org\rlabels:\rapp: pizzamaker\rmylabel: stuff\rspec:\rgroup: mykubernetes.acme.org\rscope: Namespaced\rversions:\r- name: v1\rserved: true\rstorage: true\rschema:\ropenAPIV3Schema:\rdescription: \u0026quot;A custom resource for making yummy pizzas\u0026quot; #\u0026lt;.\u0026gt;\rtype: object\rproperties:\rspec:\rtype: object\rdescription: \u0026quot;Information about our pizza\u0026quot;\rproperties:\rtoppings: #\u0026lt;.\u0026gt;\rtype: array\ritems:\rtype: string\rdescription: \u0026quot;List of toppings for our pizza\u0026quot;\rsauce: #\u0026lt;.\u0026gt;\rtype: string\rdescription: \u0026quot;The name of the sauce to use on our pizza\u0026quot;\rnames:\rkind: Pizza #\u0026lt;.\u0026gt;\rlistKind: PizzaList\rplural: pizzas\rsingular: pizza\rshortNames:\r- pz\rkubectl create namespace pizzahat\rkubectl config set-context --current --namespace=pizzahat\rkubectl apply -f apps/pizzas/pizza-crd.yaml\rFait maintenant partie de l\u0026rsquo;API\nkubectl get crds | grep pizza\rRésultat\nNAME CREATED AT\rpizzas.mykubernetes.acme.org 2022-01-23T16:26:11Z\rkubectl api-resources | grep pizzas\rRésultat\npizzas pz mykubernetes.acme.org true Pizza\rDéploiement de l\u0026rsquo;opérateur\nvim apps/pizzas/pizza-deployment.yaml\rpizza-deployment.yaml\napiVersion: rbac.authorization.k8s.io/v1\rkind: ClusterRole\rmetadata:\rname: quarkus-operator-example\rrules:\r- apiGroups:\r- ''\rresources:\r- pods\rverbs:\r- get\r- list\r- watch\r- create\r- update\r- delete\r- patch\r- apiGroups:\r- apiextensions.k8s.io\rresources:\r- customresourcedefinitions\rverbs:\r- list\r- apiGroups:\r- mykubernetes.acme.org\rresources:\r- pizzas\rverbs:\r- list\r- watch\r---\rapiVersion: v1\rkind: ServiceAccount\rmetadata:\rname: quarkus-operator-example\r---\rapiVersion: rbac.authorization.k8s.io/v1\rkind: ClusterRoleBinding\rmetadata:\rname: quarkus-operator-example\rsubjects:\r- kind: ServiceAccount\rname: quarkus-operator-example\rnamespace: pizzahat\rroleRef:\rkind: ClusterRole\rname: quarkus-operator-example\rapiGroup: rbac.authorization.k8s.io\r---\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: quarkus-operator-example\rspec:\rselector:\rmatchLabels:\rapp: quarkus-operator-example\rreplicas: 1\rtemplate:\rmetadata:\rlabels:\rapp: quarkus-operator-example\rspec:\rserviceAccountName: quarkus-operator-example\rcontainers:\r- image: quay.io/rhdevelopers/pizza-operator:1.0.1\rname: quarkus-operator-example\rimagePullPolicy: IfNotPresent\rkubectl apply -f apps/pizzas/pizza-deployment.yaml\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rquarkus-operator-example-5f5bf777bc-glfg9 1/1 Running 0 58s\rFaire des pizzas\nvim apps/pizzas/cheese-pizza.yaml\rcheese-pizza.yaml\napiVersion: mykubernetes.acme.org/v1\rkind: Pizza\rmetadata:\rname: cheesep\rspec:\rtoppings:\r- mozzarella\rsauce: regular\rkubectl apply -f apps/pizzas/cheese-pizza.yaml\rkubectl get pizzas\rNAME AGE\rcheesep 4s\rkubectl describe pizza cheesep\rName: cheesep\rNamespace: pizzahat\rLabels: \u0026lt;none\u0026gt;\rAnnotations: kubectl.kubernetes.io/last-applied-configuration:\r{\u0026quot;apiVersion\u0026quot;:\u0026quot;mykubernetes.acme.org/v1beta2\u0026quot;,\u0026quot;kind\u0026quot;:\u0026quot;Pizza\u0026quot;,\u0026quot;metadata\u0026quot;:{\u0026quot;annotations\u0026quot;:{},\u0026quot;name\u0026quot;:\u0026quot;cheesep\u0026quot;,\u0026quot;namespace\u0026quot;:\u0026quot;pizzahat\u0026quot;},\u0026quot;spec\u0026quot;:...\rAPI Version: mykubernetes.acme.org/v1beta2\rKind: Pizza\r...\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rcheesep-pod 0/1 Completed 0 3s\rquarkus-operator-example-5f5bf777bc-glfg9 1/1 Running 0 44m\rEt vérifiez les logs du Pod de fromage :\nkubectl logs cheesep-pod\r__ ____ __ _____ ___ __ ____ ______\r--/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/\r-/ /_/ / /_/ / __ |/ , _/ ,\u0026lt; / /_/ /\\ \\\r--\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/\r2022-07-23 09:03:11,537 INFO [io.quarkus] (main) pizza-maker 1.0-SNAPSHOT (powered by Quarkus 1.4.0.CR1) started in 0.006s.\r2022-07-23 09:03:11,537 INFO [io.quarkus] (main) Profile prod activated.\r2022-07-23 09:03:11,537 INFO [io.quarkus] (main) Installed features: [cdi]\rDoing The Base\rAdding Sauce regular\rAdding Toppings [mozzarella]\rBaking\rBaked\rReady For Delivery\r2022-01-23 09:03:12,038 INFO [io.quarkus] (main) pizza-maker stopped in 0.000s\rFaire plus de pizzas\nvim apps/pizzas/meat-lovers.yaml\rmeat-lovers.yaml\napiVersion: mykubernetes.acme.org/v1\rkind: Pizza\rmetadata:\rname: meatsp\rspec:\rtoppings:\r- mozzarella\r- pepperoni\r- sausage\r- bacon\rsauce: extra\rvim apps/pizzas/veggie-lovers.yaml\rapiVersion: mykubernetes.acme.org/v1\rkind: Pizza\rmetadata:\rname: veggiep\rspec:\rtoppings:\r- mozzarella\r- black olives\rsauce: extra\rkubectl apply -f apps/pizzas/meat-lovers.yaml\rkubectl apply -f apps/pizzas/veggie-lovers.yaml\rkubectl get pizzas --all-namespaces\rManger toutes les pizzas\nkubectl delete pizzas --all\rSupprimer les ressources\nkubectl delete all --all\rCréer un peu de Kafka Kafka pour Minikube Créez un nouvel espace de nom pour cette expérience :\nkubectl create namespace franz\rkubectl config set-context --current --namespace=franz\rDéployer l\u0026rsquo;opérateur Kafka :\ncurl -sL https://github.com/operator-framework/operator-lifecycle-manager/releases/download/v0.20.0/install.sh | bash -s v0.20.0\rkubectl create -f https://operatorhub.io/install/strimzi-kafka-operator.yaml\rkubectl get csv\rAttendez un peu jusqu\u0026rsquo;à l\u0026rsquo;état succès :\nwatch kubectl get csv\rNAME DISPLAY VERSION REPLACES PHASE\rstrimzi-cluster-operator.v0.27.1 Strimzi 0.27.1 strimzi-cluster-operator.v0.27.0 Succeeded\rDémarrer une veille dans un autre terminal :\nwatch kubectl get pods\rEnsuite, déployez la ressource en demandant un cluster Kafka :\nvim apps/kubefiles/mykafka.yml\rmykafka.yml\napiVersion: kafka.strimzi.io/v1beta2\rkind: Kafka\rmetadata:\rname: my-cluster\rspec:\rkafka:\rversion: 3.0.0\rreplicas: 3\rlisteners:\r- name: plain\rport: 9092\rtype: internal\rtls: false\r- name: tls\rport: 9093\rtype: internal\rtls: true\rconfig:\roffsets.topic.replication.factor: 3\rtransaction.state.log.replication.factor: 3\rtransaction.state.log.min.isr: 2\rlog.message.format.version: '3.0'\rinter.broker.protocol.version: '3.0'\rstorage:\rtype: ephemeral\rzookeeper:\rreplicas: 3\rstorage:\rtype: ephemeral\rentityOperator:\rtopicOperator: {}\ruserOperator: {}\rkubectl apply -f apps/kubefiles/mykafka.yml\rRésultat :\nNAME READY STATUS RESTARTS AGE\rmy-cluster-entity-operator-66676cb9fb-fzckz 2/2 Running 0 29s\rmy-cluster-kafka-0 2/2 Running 0 60s\rmy-cluster-kafka-1 2/2 Running 0 60s\rmy-cluster-kafka-2 2/2 Running 0 60s\rmy-cluster-zookeeper-0 2/2 Running 0 92s\rmy-cluster-zookeeper-1 2/2 Running 0 92s\rmy-cluster-zookeeper-2 2/2 Running 0 92s\rkubectl get kafkas\rNAME DESIRED KAFKA REPLICAS DESIRED ZK REPLICAS READY WARNINGS\rmy-cluster 3 3 True True\rSupprimer les ressources\nkubectl delete namespace pizzahat\rkubectl delete -f apps/pizzas/pizza-crd.yaml\rkubectl delete kafka my-cluster\rkubectl delete namespace franz\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/d%C3%A9butant/pod-replica-deployment/","title":"Pod, Replicaset, Deployment","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Commencez par créer un espace de noms dans lequel vous pourrez travailler :\nkubectl create namespace myspace\rkubectl config set-context --current --namespace=myspace\rPod Créer un naked pod :\nObservez le cycle de vie du pod :\nterminal 2 :\nwatch kubectl get pods\rNAME READY STATUS RESTARTS AGE\rquarkus-demo 0/1 ContainerCreating 0 10s\rDe la création de conteneurs à l\u0026rsquo;exécution avec Ready 1/1 :\nNAME READY STATUS RESTARTS AGE\rquarkus-demo 1/1 Running 0 18s\rVérifiez la demande dans le Pod :\nkubectl exec -it quarkus-demo /bin/sh\rExécutez la commande suivante. Notez que, comme vous êtes dans l\u0026rsquo;instance du conteneur, le nom d\u0026rsquo;hôte est localhost.\ncurl localhost:8080\rSupersonic Subatomic Java with Quarkus quarkus-demo:1\rexit\rSupprimons le Pod précédent :\nkubectl delete pod quarkus-demo\rterminal 2\nwatch kubectl get pods\rNAME READY STATUS RESTARTS AGE\rquarkus-demo 0/1 Terminating 0 9m35s\rNo resources found in myspace namespace.\rLe pod Naked disparaît à jamais.\nUn pod naked est un pod nue et il ne sera pas replanifier en cas d\u0026rsquo;erreur sur le pod ou de suppression.\nReplicaset Créer un replicaset :\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: apps/v1\rkind: ReplicaSet\rmetadata:\rname: rs-quarkus-demo\rspec:\rreplicas: 3\rselector:\rmatchLabels:\rapp: quarkus-demo\rtemplate:\rmetadata:\rlabels:\rapp: quarkus-demo\renv: dev\rspec:\rcontainers:\r- name: quarkus-demo\rimage: quay.io/rhdevelopers/quarkus-demo:v1\rEOF\rObtenez les pods avec des étiquettes :\nterminal 2\nwatch kubectl get pods --show-labels\rNAME READY STATUS RESTARTS AGE LABELS\rrs-quarkus-demo-jd6jk 1/1 Running 0 58s app=quarkus-demo,env=dev\rrs-quarkus-demo-mlnng 1/1 Running 0 58s app=quarkus-demo,env=dev\rrs-quarkus-demo-t26gt 1/1 Running 0 58s app=quarkus-demo,env=dev\rAfficher les replicaset créé :\nkubectl get rs\rNAME DESIRED CURRENT READY AGE\rrs-quarkus-demo 3 3 3 79s\rDécrire le replicaset\nkubectl describe rs rs-quarkus-demo\rLes pods sont la \u0026ldquo;propriété\u0026rdquo; du ReplicaSet :\nkubectl get pod rs-quarkus-demo-mlnng -o json | jq \u0026quot;.metadata.ownerReferences[]\u0026quot;\r{\r\u0026quot;apiVersion\u0026quot;: \u0026quot;apps/v1\u0026quot;,\r\u0026quot;blockOwnerDeletion\u0026quot;: true,\r\u0026quot;controller\u0026quot;: true,\r\u0026quot;kind\u0026quot;: \u0026quot;ReplicaSet\u0026quot;,\r\u0026quot;name\u0026quot;: \u0026quot;rs-quarkus-demo\u0026quot;,\r\u0026quot;uid\u0026quot;: \u0026quot;1ed3bb94-dfa5-40ef-8f32-fbc9cf265324\u0026quot;\r}\rSupprimez maintenant un pod, tout en regardant les pods :\nkubectl delete pod rs-quarkus-demo-mlnng\rEt une nouvelle pod va naître pour le remplacer :\nNAME READY STATUS RESTARTS AGE LABELS\rrs-quarkus-demo-2txwk 0/1 ContainerCreating 0 2s app=quarkus-demo,env=dev\rrs-quarkus-demo-jd6jk 1/1 Running 0 109s app=quarkus-demo,env=dev\rrs-quarkus-demo-t26gt 1/1 Running 0 109s app=quarkus-demo,env=dev\rSupprimez le ReplicaSet pour supprimer tous les pods associés :\nkubectl delete rs rs-quarkus-demo\rDeploiement Créer un déploiement de 3 replicaset d\u0026rsquo;un même conteneur.\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: quarkus-demo-deployment\rspec:\rreplicas: 3\rselector:\rmatchLabels:\rapp: quarkus-demo\rtemplate:\rmetadata:\rlabels:\rapp: quarkus-demo\renv: dev\rspec:\rcontainers:\r- name: quarkus-demo\rimage: quay.io/rhdevelopers/quarkus-demo:v1\rimagePullPolicy: Always\rports:\r- containerPort: 8080\rEOF\rkubectl get pods --show-labels\rNAME READY STATUS RESTARTS AGE LABELS\rquarkus-demo-deployment-5979886fb7-c888m 1/1 Running 0 17s app=quarkus-demo,env=dev,pod-template-hash=5979886fb7\rquarkus-demo-deployment-5979886fb7-gdtnz 1/1 Running 0 17s app=quarkus-demo,env=dev,pod-template-hash=5979886fb7\rquarkus-demo-deployment-5979886fb7-grf59 1/1 Running 0 17s app=quarkus-demo,env=dev,pod-template-hash=5979886f\rExecuter une commande shell dans le pods :\nkubectl exec -it quarkus-demo-deployment-5979886fb7-c888m -- curl localhost:8080\rSupersonic Subatomic Java with Quarkus quarkus-demo-deployment-5979886fb7-c888m:1\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/d%C3%A9butant/","title":"Débutant","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/%C3%A9l%C3%A9mentaire/liveness-readiness/","title":"Liveness &amp; Readiness","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Assurez-vous que vous êtes dans le bon espace de noms :\nkubectl config set-context --current --namespace=myspace\rAssurez-vous que rien d\u0026rsquo;autre n\u0026rsquo;est déployé :\nkubectl get all\rNo resources found in myspace namespace.\rDéployez une application avec le jeu de sondes Live and Ready :\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: myboot\rspec:\rreplicas: 3\rselector:\rmatchLabels:\rapp: myboot\rtemplate:\rmetadata:\rlabels:\rapp: myboot\renv: dev\rspec:\rcontainers:\r- name: myboot\rimage: quay.io/rhdevelopers/myboot:v1\rimagePullPolicy: Always\rports:\r- containerPort: 8080\rresources:\rrequests:\rmemory: \u0026quot;300Mi\u0026quot;\rcpu: \u0026quot;250m\u0026quot; # 1/4 core\rlimits:\rmemory: \u0026quot;400Mi\u0026quot;\rcpu: \u0026quot;1000m\u0026quot; # 1 core\rlivenessProbe:\rhttpGet:\rport: 8080\rpath: /\rinitialDelaySeconds: 10\rperiodSeconds: 5\rtimeoutSeconds: 2\rreadinessProbe:\rhttpGet:\rpath: /health\rport: 8080\rinitialDelaySeconds: 10\rperiodSeconds: 3\rEOF\rDécrivez le déploiement :\nkubectl describe deployment myboot\r...\rImage: quay.io/rhdevelopers/myboot:v1\rPort: 8080/TCP\rHost Port: 0/TCP\rLimits:\rcpu: 1\rmemory: 400Mi\rRequests:\rcpu: 250m\rmemory: 300Mi\rLiveness: http-get http://:8080/ delay=10s timeout=2s period=5s #success=1 #failure=3\rReadiness: http-get http://:8080/health delay=10s timeout=1s period=3s #success=1 #failure=3\r...\rDéployer un service :\nkubectl apply -f apps/kubefiles/myboot-service.yml\rCréer les variables IP et PORT\nIP=$(minikube ip)\rPORT=$(kubectl get service/myboot -o jsonpath=\u0026quot;{.spec.ports[*].nodePort}\u0026quot;)\rRéaliser une requete sur le service :\ncurl $IP:$PORT\rEt lancez le script de la boucle :\nwhile true\rdo curl $IP:$PORT\rsleep .3\rdone\rChangez l\u0026rsquo;image :\nkubectl set image deployment/myboot myboot=quay.io/rhdevelopers/myboot:v2\rEt remarquez la mise à jour sans erreur :\nAloha from Spring Boot! 131 on myboot-845968c6ff-k4rvb\rAloha from Spring Boot! 134 on myboot-845968c6ff-9wvt9\rAloha from Spring Boot! 122 on myboot-845968c6ff-9824z\rBonjour from Spring Boot! 0 on myboot-8449d5468d-m88z4\rBonjour from Spring Boot! 1 on myboot-8449d5468d-m88z4\rAloha from Spring Boot! 135 on myboot-845968c6ff-9wvt9\rAloha from Spring Boot! 133 on myboot-845968c6ff-k4rvb\rAloha from Spring Boot! 137 on myboot-845968c6ff-9wvt9\rBonjour from Spring Boot! 3 on myboot-8449d5468d-m88z4\rRegardez les points d\u0026rsquo;extrémité pour voir quels pods font partie du service :\nkubectl get endpoints myboot -o json | jq '.subsets[].addresses[].ip'\rCe sont les IP des Pods qui ont passé leur test de préparation :\n\u0026quot;10.129.2.40\u0026quot;\r\u0026quot;10.130.2.37\u0026quot;\r\u0026quot;10.130.2.38\u0026quot;\rReadiness Probe Exec en un seul Pod et changer son indicateur de disponibilité :\nkubectl exec -it myboot-845968c6ff-k5lcb /bin/bash\rcurl localhost:8080/misbehave\rexit\rVérifiez que le pod n\u0026rsquo;est plus prêt :\nNAME READY STATUS RESTARTS AGE\rmyboot-845968c6ff-9wshg 1/1 Running 0 11m\rmyboot-845968c6ff-k5lcb 0/1 Running 0 12m\rmyboot-845968c6ff-zsgx2 1/1 Running 0 11m\rMaintenant, vérifiez les points de terminaison :\nkubectl get endpoints myboot -o json | jq '.subsets[].addresses[].ip'\rEt ce pod est maintenant absent de l\u0026rsquo;équilibreur de charge du service :\n\u0026quot;10.130.2.37\u0026quot;\r\u0026quot;10.130.2.38\u0026quot;\rCe qui est aussi une évidence dans la boucle de la boucle :\nAloha from Spring Boot! 845 on myboot-845968c6ff-9wshg\rAloha from Spring Boot! 604 on myboot-845968c6ff-zsgx2\rAloha from Spring Boot! 846 on myboot-845968c6ff-9wshg\rLiveness Probe kubectl set image deployment/myboot myboot=quay.io/rhdevelopers/myboot:v3\rLaissez le déploiement se terminer sur les 3 répliques :\nwatch kubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-56659c9d69-6sglj 1/1 Running 0 2m2s\rmyboot-56659c9d69-mdllq 1/1 Running 0 97s\rmyboot-56659c9d69-zjt6q 1/1 Running 0 72s\rEt comme on le voit dans la boucle de curl/poller :\nJambo from Spring Boot! 40 on myboot-56659c9d69-mdllq\rJambo from Spring Boot! 26 on myboot-56659c9d69-zjt6q\rJambo from Spring Boot! 71 on myboot-56659c9d69-6sglj\rModifiez le déploiement pour qu\u0026rsquo;il pointe vers l\u0026rsquo;URL /alive :\nkubectl edit deployment myboot\rEt changez la sonde de Liveness probe :\n...\rspec:\rcontainers:\r- image: quay.io/rhdevelopers/myboot:v3\rimagePullPolicy: Always\rlivenessProbe:\rfailureThreshold: 3\rhttpGet:\rpath: /alive\rport: 8080\rscheme: HTTP\rinitialDelaySeconds: 10\rperiodSeconds: 5\rsuccessThreshold: 1\rtimeoutSeconds: 2\rname: myboot\r...\rSauvegardez et fermez l\u0026rsquo;éditeur, ce qui permet à cette modification d\u0026rsquo;être appliquée.\nwatch kubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-558b4f8678-nw762 1/1 Running 0 59s\rmyboot-558b4f8678-qbrgc 1/1 Running 0 81s\rmyboot-558b4f8678-z7f9n 1/1 Running 0 36s\rMaintenant, choisissez un pod, exécutez-la et tirez dessus :\nkubectl exec -it myboot-558b4f8678-qbrgc /bin/bash\rcurl localhost:8080/shot\rEt vous verrez qu\u0026rsquo;il sera redémarré :\nNAME READY STATUS RESTARTS AGE\rmyboot-558b4f8678-nw762 1/1 Running 0 4m7s\rmyboot-558b4f8678-qbrgc 1/1 Running 1 4m29s\rmyboot-558b4f8678-z7f9n 1/1 Running 0 3m44s\rDe plus, votre exécution sera terminée :\nkubectl exec -it myboot-558b4f8678-qbrgc /bin/bash\rcurl localhost:8080/shot\rI have been shot in the head1000610000@myboot-558b4f8678-qbrgc:/app$ command terminated with exit code 137\rEt vos utilisateurs finaux ne verront pas d\u0026rsquo;erreurs :\nJambo from Spring Boot! 174 on myboot-558b4f8678-z7f9n\rJambo from Spring Boot! 11 on myboot-558b4f8678-qbrgc\rJambo from Spring Boot! 12 on myboot-558b4f8678-qbrgc\rJambo from Spring Boot! 206 on myboot-558b4f8678-nw762\rJambo from Spring Boot! 207 on myboot-558b4f8678-nw762\rJambo from Spring Boot! 175 on myboot-558b4f8678-z7f9n\rJambo from Spring Boot! 176 on myboot-558b4f8678-z7f9n\rSupprimer les ressources\nkubectl delete deployment myboot\rkubectl delete service myboot\rStartup Probe Certaines applications nécessitent un temps de démarrage supplémentaire lors de leur première initialisation.\nIl peut s\u0026rsquo;avérer difficile d\u0026rsquo;intégrer ce scénario dans les sondes de disponibilité/préparation car vous devez les configurer pour qu\u0026rsquo;elles aient un comportement normal afin de détecter les anomalies pendant le temps d\u0026rsquo;exécution et, en outre, pour couvrir le long temps de démarrage.\nLes sondes de démarrage résolvent ce problème, car une fois que la sonde de démarrage a réussi, le reste des sondes prend le relais.\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: myboot\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot\rtemplate:\rmetadata:\rlabels:\rapp: myboot\renv: dev\rspec:\rcontainers:\r- name: myboot\rimage: quay.io/rhdevelopers/myboot:zoombie\rimagePullPolicy: Always\rports:\r- containerPort: 8080\rresources:\rrequests:\rmemory: \u0026quot;300Mi\u0026quot;\rcpu: \u0026quot;250m\u0026quot; # 1/4 core\rlimits:\rmemory: \u0026quot;400Mi\u0026quot;\rcpu: \u0026quot;1000m\u0026quot; # 1 core\rlivenessProbe:\rhttpGet:\rport: 8080\rpath: /\rinitialDelaySeconds: 10\rperiodSeconds: 5\rtimeoutSeconds: 2\rreadinessProbe:\rhttpGet:\rpath: /health\rport: 8080\rinitialDelaySeconds: 10\rperiodSeconds: 3\rstartupProbe:\rhttpGet:\rpath: /alive\rport: 8080\rfailureThreshold: 12\rperiodSeconds: 5\rEOF\rLa sonde de démarrage attend une minute (5 * 12) pour démarrer l\u0026rsquo;application.\nL\u0026rsquo;application actuelle renvoie une erreur 503 dans le endpoint /alive, elle ne réussira donc jamais à démarrer et la restartPolicy est appliquée.\nwatch kubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-579cc5cc47-2bk5p 0/1 Running 0 67s\rAttendez 60 secondes jusqu\u0026rsquo;à ce que vous voyiez que le pod est redémarré.\nEt vous verrez qu\u0026rsquo;il a redémarré :\nNAME READY STATUS RESTARTS AGE\rmyboot-579cc5cc47-2bk5p 0/1 Running 1 3m7s\rPour que le pod réussisse, exécutez-la et faites-la renaître :\nkubectl exec -it myboot-579cc5cc47-2bk5p /bin/bash\rcurl localhost:8080/reborn\rEt enfin, c\u0026rsquo;est parti :\nNAME READY STATUS RESTARTS AGE\rmyboot-579cc5cc47-2bk5p 1/1 Running 1 3m41s\rDécrire le pod pour obtenir les statistiques des sondes :\nkubectl describe pod myboot-579cc5cc47-2bk5p\rLimits:\rcpu: 1\rmemory: 400Mi\rRequests:\rcpu: 250m\rmemory: 300Mi\rLiveness: http-get http://:8080/ delay=10s timeout=2s period=5s #success=1 #failure=3\rReadiness: http-get http://:8080/health delay=10s timeout=1s period=3s #success=1 #failure=3\rStartup: http-get http://:8080/alive delay=0s timeout=1s period=5s #success=1 #failure=12\rEnvironment: \u0026lt;none\u0026gt;\rMounts:\rSupprimer les ressources\nkubectl delete deployment myboot\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/d%C3%A9butant/services/","title":"Service","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Cela fait suite à la création du déploiement dans le chapitre précédent.\nAssurez-vous que vous êtes dans le bon espace de noms :\nkubectl config set-context --current --namespace=myspace\rAssurez-vous que vous avez le Déploiement :\nkubectl get deployments\rNAME READY UP-TO-DATE AVAILABLE AGE\rquarkus-demo-deployment 3/3 3 3 8m33s\rAssurez-vous que vous avez un RS :\nkubectl get rs\rNAME DESIRED CURRENT READY AGE\rquarkus-demo-deployment-5979886fb7 3 3 3 8m56s\rAssurez-vous d\u0026rsquo;avoir des Pods :\nkubectl get pods\rNAME READY STATUS RESTARTS AGE\rquarkus-demo-deployment-5979886fb7-c888m 1/1 Running 0 9m17s\rquarkus-demo-deployment-5979886fb7-gdtnz 1/1 Running 0 9m17s\rquarkus-demo-deployment-5979886fb7-grf59 1/1 Running 0 9m17s\rCréer un service\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: v1\rkind: Service\rmetadata:\rname: the-service\rspec:\rselector:\rapp: quarkus-demo\rports:\r- protocol: TCP\rport: 80\rtargetPort: 8080\rtype: LoadBalancer\rEOF\rwatch kubectl get services\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\rmyapp LoadBalancer 172.30.103.41 \u0026lt;pending\u0026gt; 8080:31974/TCP 4s\rminikube addons enable ingress\rkubectl get pods -n ingress-nginx\rNAME READY STATUS RESTARTS AGE\ringress-nginx-admission-create-g9g49 0/1 Completed 0 11m\ringress-nginx-admission-patch-rqp78 0/1 Completed 1 11m\ringress-nginx-controller-59b45fb494-26npt 1/1 Running 0 11m\rminikube tunnel\rwatch kubectl get services\rNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\rthe-service LoadBalancer 10.111.248.227 10.111.248.227 80:32591/TCP 52m\rCréer les variables IP et PORT :\nminikube service the-service --url -n myspace\rhttp://172.17.0.15:31637\rcurl $IP:$PORT\rSupersonic Subatomic Java with Quarkus quarkus-demo-deployment-5979886fb7-grf59:1\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/%C3%A9l%C3%A9mentaire/configmap/","title":"Configmap","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  ConfigMap est la ressource Kubernetes qui vous permet d\u0026rsquo;externaliser la configuration de votre application.\nLa configuration d\u0026rsquo;une application est tout ce qui est susceptible de varier entre les déploiements (staging, production, environnements de développement, etc).\nThe Twelve-Factor App\nVariables d\u0026rsquo;environnement\nMyRESTController.java comprend un petit morceau de code qui s\u0026rsquo;adresse à l\u0026rsquo;environnement :\n@RequestMapping(\u0026quot;/configure\u0026quot;)\rpublic String configure() {\rString databaseConn = environment.getProperty(\u0026quot;DBCONN\u0026quot;,\u0026quot;Default\u0026quot;);\rString msgBroker = environment.getProperty(\u0026quot;MSGBROKER\u0026quot;,\u0026quot;Default\u0026quot;);\rString hello = environment.getProperty(\u0026quot;GREETING\u0026quot;,\u0026quot;Default\u0026quot;);\rString love = environment.getProperty(\u0026quot;LOVE\u0026quot;,\u0026quot;Default\u0026quot;);\rreturn \u0026quot;Configuration: \\n\u0026quot;\r+ \u0026quot;databaseConn=\u0026quot; + databaseConn + \u0026quot;\\n\u0026quot;\r+ \u0026quot;msgBroker=\u0026quot; + msgBroker + \u0026quot;\\n\u0026quot;\r+ \u0026quot;hello=\u0026quot; + hello + \u0026quot;\\n\u0026quot;\r+ \u0026quot;love=\u0026quot; + love + \u0026quot;\\n\u0026quot;;\r}\rLes variables d\u0026rsquo;environnement peuvent être manipulées au niveau du déploiement. Les modifications entraînent le redéploiement du Pod.\nDéploiement de myboot :\nCréer un fichier de déploiement\nvi apps/kubefiles/myboot-deployment.yml\rmyboot-deployment.yml\napiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot\rname: myboot\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot\rtemplate:\rmetadata:\rlabels:\rapp: myboot\rspec:\rcontainers:\r- name: myboot\rimage: quay.io/rhdevelopers/myboot:v2\rports:\r- containerPort: 8080\rkubectl apply -f apps/kubefiles/myboot-deployment.yml\rDéployer le service myboot :\nvi apps/kubefiles/myboot-service.yml\rmyboot-service.yml\napiVersion: v1\rkind: Service\rmetadata:\rname: myboot\rlabels:\rapp: myboot\rspec:\rports:\r- name: http\rport: 8080\rselector:\rapp: myboot\rtype: LoadBalancer\rkubectl apply -f apps/kubefiles/myboot-service.yml\rEt regardez l\u0026rsquo;état du pod :\nwatch kubectl get pods\rCréer les variables IP et PORT :\nIP=$(minikube ip -p devnation)\rPORT=$(kubectl get service/myboot -o jsonpath=\u0026quot;{.spec.ports[*].nodePort}\u0026quot;)\rRéaliser une requete sur le service :\ncurl $IP:$PORT\rcurl $IP:$PORT/configure\rConfiguration for : myboot-66d7d57687-jsbz7\rdatabaseConn=Default\rmsgBroker=Default\rgreeting=Default\rlove=Default\rDéfinir les variables d\u0026rsquo;environnement\nkubectl set env deployment/myboot GREETING=\u0026quot;namaste\u0026quot;\rkubectl set env deployment/myboot LOVE=\u0026quot;Aloha\u0026quot;\rkubectl set env deployment/myboot DBCONN=\u0026quot;jdbc:sqlserver://45.91.12.123:1443;user=MyUserName;password=*****;\u0026quot;\rRegardez les pods reborn :\nNAME READY STATUS RESTARTS AGE\rmyboot-66d7d57687-jsbz7 1/1 Terminating 0 5m\rmyboot-785ff6bddc-ghwpc 1/1 Running 0 13s\rcurl $IP:$PORT/configure\rConfiguration for : myboot-5fd9dd9c59-58xbh\rdatabaseConn=jdbc:sqlserver://45.91.12.123:1443;user=MyUserName;password=*****;\rmsgBroker=Default\rgreeting=namaste\rlove=Aloha\rDécrivez le déploiement :\nkubectl describe deployment myboot\r...\rContainers:\rmyboot:\rImage: quay.io/burrsutter/myboot:v1\rPort: 8080/TCP\rHost Port: 0/TCP\rEnvironment:\rGREETING: namaste\rLOVE: Aloha\rDBCONN: jdbc:sqlserver://45.91.12.123:1443;user=MyUserName;password=*****;\rMounts: \u0026lt;none\u0026gt;\rVolumes: \u0026lt;none\u0026gt;\r...\rSupprimez les variables d\u0026rsquo;environnement :\nkubectl set env deployment/myboot GREETING-\rkubectl set env deployment/myboot LOVE-\rkubectl set env deployment/myboot DBCONN-\rEt vérifiez qu\u0026rsquo;ils ont été retirés :\ncurl $IP:$PORT/configure\rConfiguration for : myboot-66d7d57687-xkgw6\rdatabaseConn=Default\rmsgBroker=Default\rgreeting=Default\rlove=Default\rCréer un ConfigMap\nkubectl create cm my-config --from-env-file=apps/config/some.properties\rkubectl get cm\rkubectl get cm my-config\rkubectl get cm my-config -o json\r...\r\u0026quot;data\u0026quot;: {\r\u0026quot;GREETING\u0026quot;: \u0026quot;jambo\u0026quot;,\r\u0026quot;LOVE\u0026quot;: \u0026quot;Amour\u0026quot;\r},\r\u0026quot;kind\u0026quot;: \u0026quot;ConfigMap\u0026quot;,\r...\rOu vous pouvez décrire l\u0026rsquo;objet ConfigMap :\nkubectl describe cm my-config\rName: my-config\rNamespace: myspace\rLabels: \u0026lt;none\u0026gt;\rAnnotations: \u0026lt;none\u0026gt;\rData\r====\rGREETING:\r====\rjambo\rLOVE:\r====\rAmour\rEvents: \u0026lt;none\u0026gt;\rMaintenant, déployez l\u0026rsquo;application avec sa requête pour le ConfigMap :\nkubectl apply -f apps/kubefiles/myboot-deployment-configuration.yml\rEt obtenir son point de terminaison de configuration :\ncurl $IP:$PORT/configure\rConfiguration for : myboot-84bfcff474-x6xnt\rdatabaseConn=Default\rmsgBroker=Default\rgreeting=jambo\rlove=Amour\rEt passez à l\u0026rsquo;autre fichier de propriétés en recréant le ConfigMap :\nkubectl delete cm my-config\rkubectl create cm my-config --from-env-file=apps/config/other.properties\rkubectl delete pod -l app=myboot\rcurl $IP:$PORT/configure\rConfiguration for : myboot-694954fc6d-nzdvx\rdatabaseConn=jdbc:sqlserver://123.123.123.123:1443;user=MyUserName;password=*****;\rmsgBroker=tcp://localhost:61616?jms.useAsyncSend=true\rhello=Default\rlove=Default\rIl y a beaucoup d\u0026rsquo;autres façons de s\u0026rsquo;amuser avec ConfigMaps, la documentation de base vous fait manipuler une spécification Pod au lieu d\u0026rsquo;un déploiement mais les résultats sont fondamentalement les mêmes https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap.\nSupprimer les ressources\nkubectl delete deployment myboot\rkubectl delete cm my-config\rkubectl delete service myboot\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/d%C3%A9butant/logs/","title":"Logs","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Il existe plusieurs façons \u0026ldquo;prêtes à la production\u0026rdquo; de collecter et de visualiser les messages de logs dans un cluster Kubernetes. Beaucoup de gens aiment certaines fonctionnalités de ELK (ElasticSearch, Logstash, Kibana) ou EFK (ElasticSearch, FluentD, Kibana).\nL\u0026rsquo;accent est mis ici sur les éléments auxquels un développeur doit avoir accès pour l\u0026rsquo;aider à comprendre le comportement de son application s\u0026rsquo;exécutant à l\u0026rsquo;intérieur d\u0026rsquo;un pod.\nAssurez-vous qu\u0026rsquo;une application (Deployment) est en cours d\u0026rsquo;exécution :\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: my-deployment\rspec:\rreplicas: 3\rselector:\rmatchLabels:\rapp: myapp\rtemplate:\rmetadata:\rlabels:\rapp: myapp\renv: dev\rspec:\rcontainers:\r- name: myapp\rimage: quay.io/rhdevelopers/myboot:v1\rimagePullPolicy: Always\rports:\r- containerPort: 8080\rEOF\rAssurez-vous que vous utilisez 3 répliques (3 pods/instances de votre demande) :\nkubectl get deployment my-deployment -o json | jq '.status.replicas'\rIf not, scale up to 3:\nkubectl scale --replicas=3 deployment/my-deployment\rNAME READY STATUS RESTARTS AGE\rmy-deployment-5dc67997c7-5bq4n 1/1 Running 0 34s\rmy-deployment-5dc67997c7-m7z9f 1/1 Running 0 34s\rmy-deployment-5dc67997c7-s4jc6 1/1 Running 0 34s\rkubectl logs my-deployment-5dc67997c7-m7z9f\r . ____ _ __ _ _\r/\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\\r( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\r\\\\/ ___)| |_)| | | | | || (_| | ) ) ) )\r' |____| .__|_| |_|_| |_\\__, | / / / /\r=========|_|==============|___/=/_/_/_/\r:: Spring Boot :: (v1.5.3.RELEASE)\rVous pouvez suivre les logs avec le paramètre -f :\nkubectl logs my-deployment-5dc67997c7-m7z9f -f\rterminal 2 :\nkubectl exec -it my-deployment-5dc67997c7-m7z9f /bin/bash\rcurl localhost:8080\rAloha from my-deployment-5dc67997c7-m7z9f\rDeploy a Service for my-deployment:\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: v1\rkind: Service\rmetadata:\rname: the-service\rspec:\rselector:\rapp: myapp\rports:\r- protocol: TCP\rport: 80\rtargetPort: 8080\rtype: LoadBalancer\rEOF\rterminal 2:\nIP=$(minikube ip)\rPORT=$(kubectl get service/the-service -o jsonpath=\u0026quot;{.spec.ports[*].nodePort}\u0026quot;)\rCurl the Service: terminal 2:\ncurl $IP:$PORT\rCommencez à envoyer la demande en boucle : terminal 2:\nwhile true\rdo curl $IP:$PORT\rsleep .3\rdone\rUtilisez ensuite Stern pour visualiser les logs de tous les pods :\nstern my-deployment\rmy-deployment-5dc67997c7-5bq4n myapp Aloha from my-deployment-5dc67997c7-5bq4n\rmy-deployment-5dc67997c7-m7z9f myapp Aloha from my-deployment-5dc67997c7-m7z9f\rmy-deployment-5dc67997c7-s4jc6 myapp Aloha from my-deployment-5dc67997c7-s4jc6\rmy-deployment-5dc67997c7-s4jc6 myapp Aloha from my-deployment-5dc67997c7-s4jc6\rNettoyer l\u0026rsquo;environnement\nkubectl delete service the-service\rkubectl delete deployment my-deployment\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/intermediare/volumes/","title":"Volumes","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Les conteneurs sont éphémères par définition, ce qui signifie que tout ce qui est stocké au moment de l\u0026rsquo;exécution est perdu lorsque le conteneur est arrêté. Cela peut poser des problèmes avec les conteneurs qui ont besoin de conserver leurs données, comme les conteneurs de base de données.\nUn volume Kubernetes est simplement un répertoire accessible aux conteneurs d\u0026rsquo;un pod. Le concept est similaire aux volumes Docker, mais dans Docker, vous faites correspondre le conteneur à un ordinateur hôte. Dans le cas des volumes Kubernetes, le support qui le soutient et son contenu sont déterminés par le type de volume particulier utilisé.\nCertains de ces types de volumes sont :\n awsElasticBlockStore azureDisk cephfs nfs local répertoire vide chemin de l\u0026rsquo;hôte  Commençons par deux exemples de Volumes.\nVolumes EmptyDir Un volume emptyDir est créé pour la première fois lorsqu\u0026rsquo;un Pod est affecté à un nœud et existe tant que ce Pod fonctionne sur ce nœud. Comme son nom l\u0026rsquo;indique, il est initialement vide. Tous les conteneurs d\u0026rsquo;un même pod peuvent lire et écrire dans le même volume emptyDir. Lorsqu\u0026rsquo;un Pod est redémarré ou supprimé, les données contenues dans le volume \u0026ldquo;emptyDir\u0026rdquo; sont perdues à jamais.\nDéployons un service qui expose deux points de terminaison, l\u0026rsquo;un pour écrire du contenu dans un fichier et l\u0026rsquo;autre pour récupérer le contenu de ce fichier.\nvim apps/kubefiles/myboot-pod-volume.yml\rapiVersion: v1\rkind: Pod\rmetadata:\rname: myboot-demo\rspec:\rcontainers:\r- name: myboot-demo\rimage: quay.io/rhdevelopers/myboot:v4\rvolumeMounts:\r- mountPath: /tmp/demo\rname: demo-volume\rvolumes:\r- name: demo-volume\remptyDir: {}\rDans la section volumes, vous définissez le volume, et dans la section volumeMounts, comment le volume est monté à l\u0026rsquo;intérieur du conteneur.\nkubectl apply -f apps/kubefiles/myboot-pod-volume.yml\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-demo 1/1 Running 0 83s\rAccédons au conteneur et exécutons ces méthodes :\nkubectl exec -ti myboot-demo /bin/bash\rcurl localhost:8080/appendgreetingfile\rcurl localhost:8080/readgreetingfile\rJambo\rDans ce cas, le emptyDir a été défini à /tmp/demo, vous pouvez donc vérifier le contenu du répertoire en exécutant ls :\nls /tmp/demo\rgreeting.txt\rQuitter le shell du conteneur :\nexit\rEt supprimez le pod.\nkubectl delete pod myboot-demo\rEnsuite, si vous déployez à nouveau le même service, vous remarquerez que le contenu du répertoire est vide.\nkubectl exec -ti myboot-demo /bin/bash\rls /tmp/demo\rexit\rEt supprimez le pod.\nkubectl delete pod myboot-demo\remptyDir est partagé entre les conteneurs d\u0026rsquo;un même Pod. Le déploiement suivant crée un pod avec deux conteneurs montant le même volume :\nvim apps/kubefiles/myboot-pods-volume.yml\rapiVersion: v1\rkind: Pod\rmetadata:\rname: myboot-demo\rspec:\rcontainers:\r- name: myboot-demo-1 #\u0026lt;.\u0026gt;\rimage: quay.io/rhdevelopers/myboot:v4\rvolumeMounts:\r- mountPath: /tmp/demo\rname: demo-volume\r- name: myboot-demo-2 #\u0026lt;.\u0026gt;\rimage: quay.io/rhdevelopers/myboot:v4 #\u0026lt;.\u0026gt;\renv:\r- name: SERVER_PORT #\u0026lt;.\u0026gt;\rvalue: \u0026quot;8090\u0026quot;\rvolumeMounts:\r- mountPath: /tmp/demo\rname: demo-volume\rvolumes:\r- name: demo-volume #\u0026lt;.\u0026gt;\remptyDir: {}\rkubectl apply -f apps/kubefiles/myboot-pods-volume.yml\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-demo 2/2 Running 0 4s\rAccédons au premier conteneur et générons du contenu dans le répertoire /tmp/demo.\nkubectl exec -ti myboot-demo -c myboot-demo-1 /bin/bash\rcurl localhost:8080/appendgreetingfile\rexit\rEt lire le contenu du fichier dans l\u0026rsquo;autre conteneur :\nkubectl exec myboot-demo -c myboot-demo-2 \u0026quot;cat /tmp/demo/greeting.txt\u0026quot;\rJambo\rVous pouvez obtenir les informations sur le volume d\u0026rsquo;un Pod en exécutant :\nkubectl describe pod myboot-demo\rVolumes:\rdemo-volume:\rType: EmptyDir (a temporary directory that shares a pods lifetime)\rMedium:\rSizeLimit: \u0026lt;unset\u0026gt;\rSupprimer les ressources\nkubectl delete -f apps/kubefiles/myboot-pods-volume.yml\rHostPath Un volume hostPath monte un fichier ou un répertoire du système de fichiers du nœud dans le Pod.\nvim apps/kubefiles/myboot-pod-volume-hostpath.yaml\rapiVersion: v1\rkind: Pod\rmetadata:\rname: myboot-demo\rspec:\rcontainers:\r- name: myboot-demo\rimage: quay.io/rhdevelopers/myboot:v4\rvolumeMounts:\r- mountPath: /tmp/demo\rname: demo-volume\rvolumes:\r- name: demo-volume\rhostPath:\rpath: \u0026quot;/mnt/data\u0026quot;\rDans ce cas, vous définissez le répertoire de l\u0026rsquo;hôte/nœud où le contenu sera stocké.\nkubectl apply -f apps/kubefiles/myboot-pod-volume-hostpath.yaml\rMaintenant, si vous décrivez le Pod, dans la section des volumes, vous verrez :\nkubectl describe pod myboot-demo\rVolumes:\rdemo-volume:\rType: HostPath (bare host directory volume)\rPath: /mnt/data\rHostPathType:\rNotez que maintenant le contenu stocké dans /tmp/demo à l\u0026rsquo;intérieur du Pod est stocké dans le chemin de l\u0026rsquo;hôte /mnt/data, donc si le Pod meurt, le contenu n\u0026rsquo;est pas perdu. Mais cela ne résout pas tous les problèmes car si le Pod tombe en panne et qu\u0026rsquo;il est reprogrammé dans un autre nœud, les données ne seront pas dans cet autre nœud.\nVoyons un autre exemple, dans ce cas pour un volume Amazon EBS :\napiVersion: v1\rkind: Pod\rmetadata:\rname: test-ebs\rspec:\r...\rvolumes:\r- name: test-volume\rawsElasticBlockStore:\rvolumeID: \u0026lt;volume-id\u0026gt;\rfsType: ext4\rCe que nous voulons que vous remarquiez dans l\u0026rsquo;extrait précédent, c\u0026rsquo;est que vous mélangez des éléments de votre application (c\u0026rsquo;est-à-dire le conteneur, les sondes, les ports, \u0026hellip;) qui sont plus du côté du développement avec des éléments plus liés au cloud (c\u0026rsquo;est-à-dire le stockage physique), qui est plus du côté des opérations.\nPour éviter ce mélange de concepts, Kubernetes offre une certaine couche d\u0026rsquo;abstractions, de sorte que les développeurs demandent simplement de l\u0026rsquo;espace pour stocker les données (-persistent volume claim_), et l\u0026rsquo;équipe des opérations offre la configuration du stockage physique.\nSupprimer les ressources\nkubectl delete pod myboot-demo\rPersistent Volume \u0026amp; Persistent Volume Claim Un PersistentVolume (PV) est une ressource Kubernetes qui est créée par un administrateur ou dynamiquement à l\u0026rsquo;aide de Storage Classes indépendamment de Pod. Il capture les détails de l\u0026rsquo;implémentation du stockage, il peut s\u0026rsquo;agir de NFS, Ceph, iSCSI, ou d\u0026rsquo;un système de stockage spécifique au fournisseur de cloud.\nUne PersistentVolumeClaim (PVC) est une demande de stockage par un utilisateur. Il peut demander une taille de volume spécifique ou, par exemple, le mode d\u0026rsquo;accès.\nVolume persistant/claim avec hostPath Utilisons la stratégie hostPath sans la configurer directement en tant que volume, mais en utilisant le volume persistant et la réclamation de volume persistant.\nvim apps/kubefiles/demo-persistent-volume-hostpath.yaml\rkind: PersistentVolume\rapiVersion: v1\rmetadata:\rname: my-persistent-volume\rlabels:\rtype: local\rspec:\rstorageClassName: pv-demo\rcapacity:\rstorage: 100Mi\raccessModes:\r- ReadWriteOnce\rhostPath:\rpath: \u0026quot;/mnt/persistent-volume\u0026quot;\rDésormais, les informations relatives au volume ne se trouvent plus dans le pod mais dans l\u0026rsquo;objet volume persistant.\nkubectl apply -f apps/kubefiles/demo-persistent-volume-hostpath.yaml\rkubectl get pv\rNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE\rmy-persistent-volume 100Mi RWO Retain Available pv-demo 5s\rEnsuite, du côté du développeur, nous devons réclamer ce dont nous avons besoin sur le PV. Dans l\u0026rsquo;exemple suivant, nous demandons un espace de 10Mi.\nvim apps/kubefiles/myboot-persistent-volume-claim.yaml\rkind: PersistentVolumeClaim\rapiVersion: v1\rmetadata:\rname: myboot-volumeclaim\rspec:\rstorageClassName: pv-demo\raccessModes:\r- ReadWriteOnce\rresources:\rrequests:\rstorage: 10Mi\rkubectl apply -f apps/kubefiles/myboot-persistent-volume-claim.yaml\rkubectl get pvc\rNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\rmyboot-volumeclaim Bound my-persistent-volume 100Mi RWO pv-demo 3s\rLa grande différence est que maintenant, dans le pod, vous définissez simplement dans la section volumes, non pas la configuration du volume directement, mais la revendication du volume persistant à utiliser.\nvim apps/kubefiles/myboot-pod-volume-pvc.yaml\rapiVersion: v1\rkind: Pod\rmetadata:\rname: myboot-demo\rspec:\rcontainers:\r- name: myboot-demo\rimage: quay.io/rhdevelopers/myboot:v4\rvolumeMounts:\r- mountPath: /tmp/demo\rname: demo-volume\rvolumes:\r- name: demo-volume\rpersistentVolumeClaim:\rclaimName: myboot-volumeclaim\rkubectl apply -f apps/kubefiles/myboot-pod-volume-pvc.yaml\rkubectl describe pod myboot-demo\rVolumes:\rdemo-volume:\rType: PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)\rClaimName: myboot-volumeclaim\rReadOnly: false\rRemarquez que maintenant la description du pod montre que le volume n\u0026rsquo;est pas défini directement mais par le biais d\u0026rsquo;une réclamation de volume de persistance.\nkubectl delete pod myboot-demo\rkubectl get pvc\rMême si le pod a été supprimé, le PVC (et le PV) sont toujours là et doivent être supprimés manuellement.\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\rmyboot-volumeclaim Bound my-persistent-volume 100Mi RWO pv-demo 14m\rSupprimer les ressources\nkubectl delete -f apps/kubefiles/myboot-persistent-volume-claim.yaml\rkubectl delete -f apps/kubefiles/demo-persistent-volume-hostpath.yaml\rProvisonnement Statique vs Dynamique Les Persistent Volumes peuvent être provisionnés de manière dynamique ou statique.\nLe provisionnement statique permet aux administrateurs de clusters de mettre à disposition d\u0026rsquo;un cluster une unité de stockage existante. Lorsqu\u0026rsquo;il est effectué de cette manière, le PV et le PVC doivent être fournis manuellement.\nJusqu\u0026rsquo;à présent, dans le dernier exemple, vous avez vu le provisionnement statique.\nAvec le provisionnement dynamique, les administrateurs de clusters n\u0026rsquo;ont plus besoin de pré-provisionner le stockage. Au lieu de cela, il provisionne automatiquement le stockage lorsqu\u0026rsquo;il est demandé par les utilisateurs. Pour le faire fonctionner, vous devez fournir un objet Storage Class et un PVC s\u0026rsquo;y référant. Une fois le PVC créé, le périphérique de stockage et le PV sont automatiquement créés pour vous. L\u0026rsquo;objectif principal du provisionnement dynamique est de travailler avec des solutions de fournisseurs de cloud.\nNormalement, l\u0026rsquo;implémentation de Kubernetes propose une classe de stockage par défaut afin que chacun puisse démarrer rapidement avec le provisionnement dynamique. Vous pouvez obtenir des informations sur la classe de stockage par défaut en exécutant :\nkubectl get sc\rNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE\rstandard (default) k8s.io/minikube-hostpath Delete Immediate false 47d\rEnsuite, vous pouvez créer une réclamation de volume persistant qui créera automatiquement un volume persistant.\nvim apps/kubefiles/demo-dynamic-persistent.yaml\rkind: PersistentVolumeClaim\rapiVersion: v1\rmetadata:\rname: myboot-volumeclaim\rspec:\raccessModes:\r- ReadWriteOnce\rresources:\rrequests:\rstorage: 10Mi\rPuisque nous n\u0026rsquo;avons pas spécifié de classe de stockage mais qu\u0026rsquo;il y en a une définie par défaut, le PVC se réfère implicitement à celle-ci.\nkubectl apply -f apps/kubefiles/demo-dynamic-persistent.yaml\rkubectl get pvc\rNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\rmyboot-volumeclaim Pending gp2 46sç\rRemarquez que le PVC est en état d\u0026rsquo;attente, car rappelez-vous que nous créons un stockage dynamique et que cela signifie que tant que le pod ne demande pas le volume, le PVC restera en état d\u0026rsquo;attente et le PV ne sera pas créé.\nkubectl apply -f apps/kubefiles/myboot-pod-volume-pvc.yaml\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-demo 1/1 Running 0 2m36s\rLorsque le pod est en état de fonctionnement, vous pouvez obtenir les paramètres PVC et PV.\nkubectl get pvc\rNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\rmyboot-volumeclaim Bound pvc-6de4f27e-bd40-4b58-bb46-91eb08ca5bd7 1Gi RWO gp2 116s\rRemarquez que maintenant la demande de volume est liée à un volume.\nEnfin, vous pouvez vérifier que le PV a été créé automatiquement :\nkubectl get pv\nNAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE\rpvc-6de4f27e-bd40-4b58-bb46-91eb08ca5bd7 1Gi RWO Delete Bound default/myboot-volumeclaim gp2 77s\rNotez que le champ CLAIM pointe vers le PVC responsable de la création du PV.\nSupprimer les ressources\nkubectl delete -f apps/kubefiles/myboot-pod-volume-pvc.yaml\rkubectl delete -f apps/kubefiles/demo-dynamic-persistent.yaml\rSystèmes de fichiers distribués Il est important de noter que les fournisseurs de cloud computing proposent des stockages distribués afin que les données soient toujours disponibles dans tous les nœuds. Comme vous l\u0026rsquo;avez vu dans le dernier exemple, cette classe de stockage garantit que tous les nœuds voient le même contenu de disque.\nSi par exemple, vous utilisez Kubernetes on-prem ou si vous ne voulez pas relayer vers une solution fournisseur, il existe également une prise en charge des systèmes de fichiers distribués dans Kubernetes. Si c\u0026rsquo;est le cas, nous vous recommandons d\u0026rsquo;utiliser NFS, GlusterFS ou Ceph.\n"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/%C3%A9l%C3%A9mentaire/","title":"Elementaire","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/d%C3%A9butant/servicemagic/","title":"Service Magic","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Créer un namespace\nkubectl create namespace funstuff\rkubectl config set-context --current --namespace=funstuff\rDeployer une application mypython\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: mypython-deployment\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: mypython\rtemplate:\rmetadata:\rlabels:\rapp: mypython\rspec:\rcontainers:\r- name: mypython\rimage: quay.io/rhdevelopers/mypython:v1\rports:\r- containerPort: 8000\rEOF\rDeployer une application mygo\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: mygo-deployment\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: mygo\rtemplate:\rmetadata:\rlabels:\rapp: mygo\rspec:\rcontainers:\r- name: mygo\rimage: quay.io/rhdevelopers/mygo:v1\rports:\r- containerPort: 8000\rEOF\rDeployer une application mynode\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rname: mynode-deployment\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: mynode\rtemplate:\rmetadata:\rlabels:\rapp: mynode\rspec:\rcontainers:\r- name: mynode\rimage: quay.io/rhdevelopers/mynode:v1\rports:\r- containerPort: 8000\rEOF\rVérifier l\u0026rsquo;état des applications\nwatch kubectl get pods --show-labels\rNAME READY STATUS RESTARTS AGE LABELS\rmygo-deployment-6d944c5c69-kcvmk 1/1 Running 0 2m11s app=mygo,pod-template-hash=6d944c5c69\rmynode-deployment-fb5457c5-hhz7h 1/1 Running 0 2m1s app=mynode,pod-template-hash=fb5457c5\rmypython-deployment-6874f84d85-2kpjl 1/1 Running 0 3m53s app=mypython,pod-template-hash=6874f84d85\rDéployer un service générique\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f -\rapiVersion: v1\rkind: Service\rmetadata:\rname: my-service\rlabels:\rapp: mystuff\rspec:\rports:\r- name: http\rport: 8000\rselector:\rinservice: mypods\rtype: LoadBalancer\rEOF\rObserver la description de ce service\nkubectl describe service my-service\rObserver la présence de EndPoint\nkubectl get endpoints\rNAME ENDPOINTS AGE\rmy-service \u0026lt;none\u0026gt; 2m6s\rRecherche l\u0026rsquo;adresse IP du EndPoint\nkubectl get endpoints my-service -o json | jq '.subsets[].addresses[].ip'\rjq: error (at \u0026lt;stdin\u0026gt;:18): Cannot iterate over null (null)\rDéfinir les variables IP et PORT\nIP=$(minikube ip -p devnation)\rPORT=$(kubectl get service/my-service -o jsonpath=\u0026quot;{.spec.ports[*].nodePort}\u0026quot;)\rFaire une requete au service\ncurl $IP:$PORT\rFaire une boucle de requete au service\nwhile true\rdo curl $IP:$PORT\rsleep .3\rdone\rcurl: (7) Failed to connect to 35.224.233.213 port 8000: Connection refused\rcurl: (7) Failed to connect to 35.224.233.213 port 8000: Connection refused\rAjouter un label à un pod\nkubectl label pod -l app=mypython inservice=mypods\rcurl: (7) Failed to connect to 35.224.233.213 port 8000: Connection refused\rPython Hello on mypython-deployment-6874f84d85-2kpjl\rPython Hello on mypython-deployment-6874f84d85-2kpjl\rPython Hello on mypython-deployment-6874f84d85-2kpjl\rkubectl label pod -l app=mynode inservice=mypods\rPython Hello on mypython-deployment-6874f84d85-2kpjl\rPython Hello on mypython-deployment-6874f84d85-2kpjl\rNode Hello on mynode-deployment-fb5457c5-hhz7h 0\rNode Hello on mynode-deployment-fb5457c5-hhz7h 1\rPython Hello on mypython-deployment-6874f84d85-2kpjl\rPython Hello on mypython-deployment-6874f84d85-2kpjl\rPython Hello on mypython-deployment-6874f84d85-2kpjl\rkubectl label pod -l app=mygo inservice=mypods\rNode Hello on mynode-deployment-fb5457c5-hhz7h 59\rNode Hello on mynode-deployment-fb5457c5-hhz7h 60\rGo Hello on mygo-deployment-6d944c5c69-kcvmk\rPython Hello on mypython-deployment-6874f84d85-2kpjl\rPython Hello on mypython-deployment-6874f84d85-2kpjl\rRecherche les IP du EndPoint\nkubectl get endpoints my-service -o json | jq '.subsets[].addresses[].ip'\r\u0026quot;10.130.2.43\u0026quot;\r\u0026quot;10.130.2.44\u0026quot;\r\u0026quot;10.130.2.45\u0026quot;\rAfficher les pods avec les labels\nkubectl get pods -o wide\rSupprimer l\u0026rsquo;application mypython du service\nkubectl label pod -l app=mypython inservice-\rkubectl get endpoints my-service -o json | jq '.subsets[].addresses[].ip'-\r\u0026quot;10.130.2.44\u0026quot;\r\u0026quot;10.130.2.45\u0026quot;\rSupprimer le namespace\nkubectl delete namespace funstuff\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/intermediare/","title":"Intermediare","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/d%C3%A9butant/blue-green/","title":"Déploiement Blue/Green","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Créer un namespace\nkubectl create namespace myspace\rkubectl config set-context --current --namespace=myspace\rVérifier que le namespace est vide\nkubectl get all\rNo resources found in myspace namespace.\rCréer un fichier de déploiement\nmkdir -p apps/kubefiles/\rvi apps/kubefiles/myboot-deployment-resources-limits.yml\rmyboot-deployment-resources-limits.yml\napiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot\rname: myboot\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot\rtemplate:\rmetadata:\rlabels:\rapp: myboot\rspec:\rcontainers:\r- name: myboot\rimage: quay.io/rhdevelopers/myboot:v1\rports:\r- containerPort: 8080\rresources:\rrequests:\rmemory: \u0026quot;300Mi\u0026quot;\rcpu: \u0026quot;250m\u0026quot; # 1/4 core\r# NOTE: These are the same limits we tested our Docker Container with earlier\r# -m matches limits.memory and --cpus matches limits.cpu\rlimits:\rmemory: \u0026quot;400Mi\u0026quot;\rcpu: \u0026quot;1000m\u0026quot; # 1 core\rDéployer la version 1 de l\u0026rsquo;applciation myboot\nkubectl apply -f apps/kubefiles/myboot-deployment-resources-limits.yml\rScale l\u0026rsquo;application avec 2 replicas\nkubectl scale deployment/myboot --replicas=2\rVérifier l\u0026rsquo;état de l\u0026rsquo;application\nwatch kubectl get pods --show-labels\rCréer un fichier pour votre service\nvi apps/kubefiles/myboot-service.yml\rmyboot-service.yml\napiVersion: v1\rkind: Service\rmetadata:\rname: myboot\rlabels:\rapp: myboot\rspec:\rports:\r- name: http\rport: 8080\rselector:\rapp: myboot\rtype: LoadBalancer\rDéployer le service\nkubectl apply -f apps/kubefiles/myboot-service.yml\rCréer les variables d\u0026rsquo;environnement IP et Port\nIP=$(minikube ip -p devnation)\rPORT=$(kubectl get service/myboot -o jsonpath=\u0026quot;{.spec.ports[*].nodePort}\u0026quot;)\rRéaliser une requete du service\ncurl $IP:$PORT\rEt maintenant créer une boucle de requete\nwhile true\rdo curl $IP:$PORT\rsleep .3\rdone\rCréer un fichier de déploiement pour la version 2\nvi apps/kubefiles/myboot-deployment-resources-limits-v2.yml\rmyboot-deployment-resources-limits-v2.yml\napiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot-next\rname: myboot-next-5\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot-next\rtemplate:\rmetadata:\rlabels:\rapp: myboot-next\rspec:\rcontainers:\r- name: myboot\rimage: quay.io/rhdevelopers/myboot:v3\rports:\r- containerPort: 8080\rresources:\rrequests:\rmemory: \u0026quot;300000Mi\u0026quot;\rcpu: \u0026quot;250m\u0026quot; # 1/4 core\rlimits:\rmemory: \u0026quot;900000Mi\u0026quot;\rcpu: \u0026quot;1000m\u0026quot; # 1 core\rVérifiez que le nouveau pod/déploiement porte le nouveau code :\nPODNAME=$(kubectl get pod -l app=myboot-next -o name)\rkubectl exec -it $PODNAME -- curl localhost:8080\rBonjour from Spring Boot! 1 on myboot-next-66b68c6659-ftcjr\rMaintenant, mettez à jour le service unique pour pointer vers le nouveau pod et passez au Green :\nkubectl patch svc/myboot -p '{\u0026quot;spec\u0026quot;:{\u0026quot;selector\u0026quot;:{\u0026quot;app\u0026quot;:\u0026quot;myboot-next\u0026quot;}}}'\rAloha from Spring Boot! 240 on myboot-d78fb6d58-929wn\rBonjour from Spring Boot! 2 on myboot-next-66b68c6659-ftcjr\rBonjour from Spring Boot! 3 on myboot-next-66b68c6659-ftcjr\rBonjour from Spring Boot! 4 on myboot-next-66b68c6659-ftcjr\rVous déterminez que vous préférez l\u0026rsquo;hawaïen (bleu) au français (vert) et faites un rollback :\nMettez maintenant à jour le service unique pour pointer vers le nouveau pod et passez en Bleu :\nkubectl patch svc/myboot -p '{\u0026quot;spec\u0026quot;:{\u0026quot;selector\u0026quot;:{\u0026quot;app\u0026quot;:\u0026quot;myboot\u0026quot;}}}'\rBonjour from Spring Boot! 17 on myboot-next-66b68c6659-ftcjr\rAloha from Spring Boot! 257 on myboot-d78fb6d58-vqvlb\rAloha from Spring Boot! 258 on myboot-d78fb6d58-vqvlb\rSupprimer les ressources\nkubectl delete service myboot\rkubectl delete deployment myboot\rkubectl delete deployment myboot-next\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/intermediare/taints_affinity/","title":"Taints et Affinity","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Jusqu\u0026rsquo;à présent, lorsque nous déployions un Pod dans le cluster Kubernetes, il était exécuté sur n\u0026rsquo;importe quel nœud répondant aux exigences (c\u0026rsquo;est-à-dire les exigences en matière de mémoire, de CPU, \u0026hellip;).\nCependant, dans Kubernetes, il existe deux concepts qui vous permettent de configurer davantage le planificateur, de sorte que les pods soient affectés aux nœuds en fonction de certains critères commerciaux.\nPreparation Si vous exécutez ce tutoriel dans Minikube, vous devez déployer un premier noeud en utilisant le driver docker :\nminikube stop\rminikube delete --all\rminikube start --driver=docker\rSi vous avez un proxy\nminikube stop\rminikube delete --all\rminikube start --docker-env HTTPS_PROXY=$HTTPS_PROXY --docker-env HTTP_PROXY=$HTTP_PROXY --docker-env=NO_PROXY=$no_proxy\rAjouter des nœuds supplémentaires pour exécuter cette partie du tutoriel. Vérifiez le nombre de nœuds que vous avez delpoyés en exécutant :\nkubectl get nodes\rSi un seul nœud est présent, vous devez créer un nouveau nœud en suivant les étapes suivantes :\nNAME STATUS ROLES AGE VERSION\rkube Ready master 54m v1.23.1\rAyant minikube installé et dans votre PATH, puis exécutez :\nminikube node add\rkubectl get nodes\rNAME STATUS ROLES AGE VERSION\rkube Ready master 54m v1.23.1\rkube-m02 Ready \u0026lt;none\u0026gt; 2m50s v1.23.1\rTaints et Tolérance Une taint est appliquée à un nœud Kubernetes qui signale au planificateur d\u0026rsquo;éviter ou de ne pas planifier certains pods.\nUne tolérance est appliquée à la définition d\u0026rsquo;un pod et fournit une exception au taint.\nDécrivons les nœuds actuels, dans ce cas comme un cluster Minikube est utilisé, vous pouvez voir plusieurs nœuds :\nkubectl describe nodes | egrep \u0026quot;Name:|Taints:\u0026quot;\rName: minikube\rTaints: \u0026lt;none\u0026gt;\rName: minikube-m02\rTaints: \u0026lt;none\u0026gt;\rNotez que dans ce cas, les nœuds ne contient pas de taint.\nTaints Ajoutons une tache à tous les noeuds :\nkubectl taint nodes --all=true color=blue:NoSchedule\rnode/minikube tainted\rnode/minikube-m02 tainted\rLa couleur=bleue est simplement une paire clé=valeur pour identifier la taint et NoSchedule est l\u0026rsquo;effet spécifique.\nMaintenant, déployez un nouveau pod.\nvim apps/kubefiles/myboot-nginx-deployment.yml\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot\rname: myboot\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot\rtemplate:\rmetadata:\rlabels:\rapp: myboot\rspec:\rcontainers:\r- name: myboot\rimage: nginx\rports:\r- containerPort: 8080\rkubectl apply -f apps/kubefiles/myboot-nginx-deployment.yml\rkubectl get pods\rLe pod restera en statut Pending car il n\u0026rsquo;a pas de nœud programmable disponible.\nNAME READY STATUS RESTARTS AGE\rmyboot-7f889dd6d-n5z55 0/1 Pending 0 55s\rkubectl describe pod myboot-7f889dd6d-n5z55\rName: myboot-7f889dd6d-n5z55\rNamespace: kubetut\rPriority: 0\rNode: \u0026lt;none\u0026gt;\rLabels: app=myboot\rpod-template-hash=7f889dd6d\rAnnotations: openshift.io/scc: restricted\rStatus: Pending\rNode-Selectors: \u0026lt;none\u0026gt;\rTolerations: node.kubernetes.io/not-ready:NoExecute for 300s\rnode.kubernetes.io/unreachable:NoExecute for 300s\rEvents:\rType Reason Age From Message\r---- ------ ---- ---- -------\rWarning FailedScheduling \u0026lt;unknown\u0026gt; default-scheduler 0/9 nodes are available: 9 node(s) had taints that the pod didn't tolerate.\rWarning FailedScheduling \u0026lt;unknown\u0026gt; default-scheduler 0/9 nodes are available: 9 node(s) had taints that the pod didn't tolerate.\rMaintenant, enlevons une tare d\u0026rsquo;un noeud et voyons ce qui se passe :\nkubectl get nodes\rNAME STATUS ROLES AGE VERSION\rminikube Ready control-plane,master 120m v1.23.1\rminikube-m02 Ready \u0026lt;none\u0026gt; 119m v1.23.1\rChoisissez un nœud.\nkubectl taint node minikube-m02 color:NoSchedule-\rnode/minikube-m02 untainted\rkubectl describe nodes | egrep \u0026quot;Name:|Taints:\u0026quot;\rName: minikube\rTaints: color=blue:NoSchedule\rName: minikube-m02\rTaints: \u0026lt;none\u0026gt;\rEt vous devriez voir le pod en attente programmé sur le nouveau nœud non taint.\nkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-7f84d7cfc9-2m4lh 1/1 Running 0 7m\rSupprimer les ressources\nkubectl delete -f apps/kubefiles/myboot-nginx-deployment.yml\rkubectl taint node minikube-m02 color=blue:NoSchedule\rTolerations Créons un Pod mais contenant une tolérance, afin qu\u0026rsquo;il puisse être programmé vers un nœud taint.\nspec:\rtolerations:\r- key: \u0026quot;color\u0026quot;\roperator: \u0026quot;Equal\u0026quot;\rvalue: \u0026quot;blue\u0026quot;\reffect: \u0026quot;NoSchedule\u0026quot;\rcontainers:\r- name: myboot\rimage: nginx\rvim apps/kubefiles/myboot-toleration.yaml\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot\rname: myboot\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot\rtemplate:\rmetadata:\rlabels:\rapp: myboot\rspec:\rtolerations:\r- key: \u0026quot;color\u0026quot;\roperator: \u0026quot;Equal\u0026quot;\rvalue: \u0026quot;blue\u0026quot;\reffect: \u0026quot;NoSchedule\u0026quot;\rcontainers:\r- name: myboot\rimage: nginx\rports:\r- containerPort: 8080\rkubectl apply -f apps/kubefiles/myboot-toleration.yaml\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-84b457458b-mbf9r 1/1 Running 0 3m18s\rMaintenant, bien que tous les nœuds contiennent une taint, le Pod est programmé et exécuté comme nous avons défini une tolérance contre la taint color=blue.\nSupprimer les ressources\nkubectl delete -f apps/kubefiles/myboot-toleration.yaml\rPas d\u0026rsquo;exécution de taint Jusqu\u0026rsquo;à présent, vous avez vu l\u0026rsquo;effet du défaut NoSchedule qui signifie que les pods nouvellement créés ne seront pas planifiés à cet endroit, à moins qu\u0026rsquo;ils ne disposent d\u0026rsquo;une tolérance prioritaire. Mais remarquez que si nous ajoutons cette taint à un nœud qui a déjà des pods en cours d\u0026rsquo;exécution/planifiés, cette taint ne les arrêtera pas.\nChangeons cela en utilisant l\u0026rsquo;effet NoExecution.\nTout d\u0026rsquo;abord, supprimons toutes les altérations précédentes.\nkubectl taint nodes --all=true color=blue:NoSchedule-\rEnsuite, déployez un service :\nkubectl apply -f apps/kubefiles/myboot-nginx-deployment.yml\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-7f889dd6d-bkfg5 1/1 Running 0 16s\rkubectl get pod myboot-7f889dd6d-bkfg5 -o json | jq '.spec.nodeName'\r\u0026quot;minikube-m02\u0026quot;\rkubectl taint node minikube-m02 color=blue:NoExecute\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-7f889dd6d-8fm2v 1/1 Running 0 14s\rmyboot-7f889dd6d-bkfg5 1/1 Terminating 0 5m51s\rSi vous avez plus de nœuds disponibles, alors le Pod est terminé et déployé sur un autre nœud, si ce n\u0026rsquo;est pas le cas, alors le Pod restera en statut Pending.\nVous pouvez observer cette \u0026ldquo;reprogrammation\u0026rdquo; à l\u0026rsquo;aide de -o wide.\nwatch kubectl get pods -o wide\rNAME READY STATUS RESTARTS AGE IP NODE\rmyboot-7f889dd6d-b9tks 1/1 Running 0 6s 10.88.0.5 minikube\rmyboot-7f889dd6d-l897f 1/1 Terminating 0 9m11s 172.17.0.4 minikube-m02\rSupprimer les ressources\nkubectl delete -f apps/kubefiles/myboot-deployment.yml\rEt supprimer la taint NoExecute\nkubectl taint node minikube-m02 color=blue:NoExecute-\rAffinité et antiaffinité Il existe une autre façon de changer l\u0026rsquo;endroit où les Pods sont programmés en utilisant l\u0026rsquo;affinité et l\u0026rsquo;anti-affinité Node/Pod. Vous pouvez créer des règles qui non seulement interdisent les endroits où les Pods peuvent s\u0026rsquo;exécuter mais aussi qui favorisent les endroits où ils doivent s\u0026rsquo;exécuter.\nEn plus de créer des affinités entre les pods et les nœuds, vous pouvez également créer des affinités entre les pods. Vous pouvez décider qu\u0026rsquo;un groupe de pods doit toujours être déployé ensemble sur le(s) même(s) nœud(s). Des raisons telles qu\u0026rsquo;une communication réseau importante entre les Pods et vous voulez éviter les appels réseau externes ou peut-être les périphériques de stockage partagés.\nAffinité des nœuds Déployons un nouveau pod avec une affinité de nœud :\nspec:\raffinity:\rnodeAffinity:\rrequiredDuringSchedulingIgnoredDuringExecution:\rnodeSelectorTerms:\r- matchExpressions:\r- key: color\roperator: In\rvalues:\r- blue\rcontainers:\r- name: myboot\rimage: nginx\rvim apps/kubefiles/myboot-node-affinity.yml\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot\rname: myboot\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot\rtemplate:\rmetadata:\rlabels:\rapp: myboot\rspec:\raffinity:\rnodeAffinity:\rrequiredDuringSchedulingIgnoredDuringExecution:\rnodeSelectorTerms:\r- matchExpressions:\r- key: color\roperator: In\rvalues:\r- blue\rcontainers:\r- name: myboot\rimage: nginx\rports:\r- containerPort: 8080\rkubectl apply -f apps/kubefiles/myboot-node-affinity.yml\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-54d788fdc8-f6wks 0/1 Pending 0 13s\rCréons une étiquette sur un nœud correspondant à l\u0026rsquo;expression d\u0026rsquo;affinité :\nkubectl get nodes\rNAME STATUS ROLES AGE VERSION\rminikube Ready control-plane,master 27m v1.23.1\rminikube-m02 Ready \u0026lt;none\u0026gt; 25m v1.23.1\rNAME STATUS ROLES AGE VERSION\rminikube Ready control-plane,master 27m v1.23.1\rminikube-m02 Ready \u0026lt;none\u0026gt; 25m v1.23.1\rkubectl label nodes minikube-m02 color=blue\rnode/minikube-m02 labeled\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-54d788fdc8-f6wks 1/1 Running 0 7m57s\rSupprimons l\u0026rsquo;étiquette du nœud :\nkubectl label nodes minikube-m02 color-\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-54d788fdc8-f6wks 1/1 Running 0 7m57s\rComme pour les taints, la règle est définie pendant la phase d\u0026rsquo;ordonnancement, par conséquent, le Pod n\u0026rsquo;est pas supprimé.\nIl s\u0026rsquo;agit d\u0026rsquo;un exemple de règle stricte, si le planificateur de Kubernetes ne trouve pas de nœud avec l\u0026rsquo;étiquette requise, le pod est rappelé dans l\u0026rsquo;état Pending. Il est également possible de créer une règle souple, dans laquelle le planificateur Kubernetes tente de répondre aux règles, mais s\u0026rsquo;il n\u0026rsquo;y parvient pas, le pod est programmé vers n\u0026rsquo;importe quel nœud. Dans l\u0026rsquo;exemple ci-dessous, vous pouvez voir l\u0026rsquo;utilisation du mot préféré par rapport au mot requis.\nspec:\raffinity:\rnodeAffinity:\rpreferredDuringSchedulingIgnoredDuringExecution:\r- weight: 1\rpreference:\rmatchExpressions:\r- key: color\roperator: In\rvalues:\r- blue\rSupprimer les ressources\nkubectl delete -f apps/kubefiles/myboot-node-affinity.yml\rPod Affinity/Anti-Affinity Déployons un nouveau pod avec un Pod Affinity :\nspec:\raffinity:\rpodAffinity:\rrequiredDuringSchedulingIgnoredDuringExecution:\r- topologyKey: kubernetes.io/hostname (1)\rlabelSelector:\rmatchExpressions:\r- key: app\roperator: In\rvalues:\r- myboot (2)\rcontainers:\r1- La clé de l\u0026rsquo;étiquette du nœud. Si deux noeuds sont étiquetés avec cette clé et ont des valeurs identiques, l\u0026rsquo;ordonnanceur traite les deux noeuds comme étant dans la même topologie. Dans ce cas, le nom d\u0026rsquo;hôte est une étiquette qui est différente pour chaque noeud. 2- L\u0026rsquo;affinité est avec les pods étiquetés avec app=myboot.\nvim apps/kubefiles/myboot-pod-affinity.yml\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot2\rname: myboot2\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot2\rtemplate:\rmetadata:\rlabels:\rapp: myboot2\rspec:\raffinity:\rpodAffinity:\rrequiredDuringSchedulingIgnoredDuringExecution:\r- topologyKey: kubernetes.io/hostname\rlabelSelector:\rmatchExpressions:\r- key: app\roperator: In\rvalues:\r- myboot\rcontainers:\r- name: myboot\rimage: nginx\rports:\r- containerPort: 8080\rkubectl apply -f apps/kubefiles/myboot-pod-affinity.yml\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot2-784bc58c8d-j2l74 0/1 Pending 0 19s\rLe Pod myboot2 est en attente car il n\u0026rsquo;a pas pu trouver de Pod correspondant à la règle d\u0026rsquo;affinité. Déployons l\u0026rsquo;application myboot étiquetée avec app=myboot.\nkubectl apply -f apps/kubefiles/myboot-nginx-deployment.yml\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rmyboot-7f889dd6d-tr7gr 1/1 Running 0 3m27s\rmyboot2-64566b697b-snm7p 1/1 Running 0 18s\rMaintenant, les deux applications sont exécutées dans le même nœud :\nkubectl get pod myboot-7f889dd6d-tr7gr -o json | jq '.spec.nodeName'\rminikube\rkubectl get pod myboot2-64566b697b-snm7p -o json | jq '.spec.nodeName'\rminikube\rCe que vous avez vu ici est une règle stricte, vous pouvez également utiliser des règles \u0026ldquo;douces\u0026rdquo; dans Pod Affinity.\nspec:\raffinity:\rpodAntiAffinity:\rpreferredDuringSchedulingIgnoredDuringExecution:\r- weight: 1\rpodAffinityTerm:\rtopologyKey: kubernetes.io/hostname\rlabelSelector:\rmatchExpressions:\r- key: app\roperator: In\rvalues:\r- myboot\rL\u0026rsquo;anti-affinité est utilisée pour s\u0026rsquo;assurer que deux pods ne fonctionnent PAS ensemble sur le même nœud.\nspec:\raffinity:\rpodAntiAffinity:\rrequiredDuringSchedulingIgnoredDuringExecution:\r- topologyKey: kubernetes.io/hostname\rlabelSelector:\rmatchExpressions:\r- key: app\roperator: In\rvalues:\r- myboot\rDéployer un myboot3 avec une règle d\u0026rsquo;anti-affinité\nvim apps/kubefiles/myboot-pod-antiaffinity.yaml\rapiVersion: apps/v1\rkind: Deployment\rmetadata:\rlabels:\rapp: myboot3\rname: myboot3\rspec:\rreplicas: 1\rselector:\rmatchLabels:\rapp: myboot3\rtemplate:\rmetadata:\rlabels:\rapp: myboot3\rspec:\raffinity:\rpodAntiAffinity:\rrequiredDuringSchedulingIgnoredDuringExecution:\r- topologyKey: kubernetes.io/hostname\rlabelSelector:\rmatchExpressions:\r- key: app\roperator: In\rvalues:\r- myboot\rcontainers:\r- name: myboot\rimage: nginx\rports:\r- containerPort: 8080\rkubectl apply -f apps/kubefiles/myboot-pod-antiaffinity.yaml\rPuis utilisez la commande kubectl get pods -o wide pour voir quels pods atterrissent sur quels noeuds.\nkubectl get pods -o wide\rNAME READY STATUS RESTARTS AGE IP NODE\rmyboot-7f889dd6d-tr7gz 1/1 Running 0 4m27s 10.88.0.9 minikube\rmyboot2-64566b697b-snm7p 1/1 Running 0 48s 10.88.0.10 minikube\rmyboot3-78656b637r-suy1t 1/1 Running 0 1s 172.17.0.2 minikube-m02\rLe pod myboot3 est déployé dans un nœud différent de celui du pod myboot.\nSupprimer les ressources\nkubectl delete -f apps/kubefiles/myboot-pod-affinity.yml\rkubectl delete -f apps/kubefiles/myboot-pod-antiaffinity.yml\rkubectl delete -f apps/kubefiles/myboot-deployment.yml\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/intermediare/job_cronjob/","title":"Job &amp; CronJob","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Preparation Si vous exécutez ce tutoriel dans Minikube, vous devez déployer un seul noeud :\nminikube stop\rminikube delete --all\rminikube start --vm-driver=none\rLa plupart du temps, vous utilisez Kubernetes comme plateforme pour exécuter des processus \u0026ldquo;longs\u0026rdquo; dont l\u0026rsquo;objectif est de fournir des réponses à une requête entrante donnée.\nMais Kubernetes vous permet également d\u0026rsquo;exécuter des processus dont le but est d\u0026rsquo;exécuter une certaine logique (par exemple, mise à jour de la base de données, traitement par lots, \u0026hellip;) et de mourir.\nLes Jobs Kubernetes sont des tâches qui exécutent une certaine logique une fois.\nLes CronJobs de Kubernetes sont des tâches qui se répètent en suivant un modèle Cron.\nAjouter des nœuds supplémentaires pour exécuter cette partie du tutoriel. Vérifiez le nombre de nœuds que vous avez delpoyés en exécutant :\nJob Un job est créé à l\u0026rsquo;aide de la ressource Kubernetes Job :\nvim apps/kubefiles/whalesay-job.yaml\rapiVersion: batch/v1\rkind: Job\rmetadata:\rname: whale-say-job\rspec: template:\rspec:\rcontainers:\r- name: whale-say-container\rimage: docker/whalesay\rcommand: [\u0026quot;cowsay\u0026quot;,\u0026quot;Hello Kubernetes Team\u0026quot;]\rrestartPolicy: Never\rkubectl apply -f apps/kubefiles/whalesay-job.yaml\rwatch kubectl get pods\rNAME READY STATUS RESTARTS AGE\rwhale-say-job-lp4n5 0/1 ContainerCreating 0 9s\rNAME READY STATUS RESTARTS AGE\rwhale-say-job-lp4n5 1/1 Running 0 19s\rNAME READY STATUS RESTARTS AGE\rwhale-say-job-lp4n5 0/1 Completed 0 25s\rVous pouvez obtenir des emplois comme toute autre ressource Kubernetes :\nkubectl get jobs\rNAME COMPLETIONS DURATION AGE\rwhale-say-job 1/1 20s 36s\rPour obtenir le résultat de l\u0026rsquo;exécution du job :\nkubectl logs whale-say-job-lp4n5\r _______________________\r\u0026lt; Hello Kubernetes Team \u0026gt;\r-----------------------\r\\\r\\\r\\\r## .\r## ## ## ==\r## ## ## ## ===\r/\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;___/ ===\r~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~\r\\______ o __/\r\\ \\ __/\r\\____\\______/\rSupprimer les ressources\nkubectl delete -f apps/kubefiles/whalesay-job.yaml\rCronJobs Un CronJob est défini à l\u0026rsquo;aide de la ressource Kubernetes CronJob :\nvim apps/kubefiles/whalesay-cronjob.yaml\rapiVersion: batch/v1beta1\rkind: CronJob\rmetadata:\rname: whale-say-cronjob\rspec:\rschedule: \u0026quot;*/1 * * * *\u0026quot; (1)\rjobTemplate:\rspec:\rtemplate:\rspec:\rcontainers:\r- name: whale-say-container\rimage: docker/whalesay\rcommand: [\u0026quot;cowsay\u0026quot;,\u0026quot;Hello Kubernetes Team\u0026quot;]\rrestartPolicy: Never\r1- Le travail est exécuté toutes les minutes.\nkubectl apply -f apps/kubefiles/whalesay-cronjob.yaml\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rAucun Pod n\u0026rsquo;est en cours d\u0026rsquo;exécution car le CronJob est exécuté après 1 minute.\nkubectl get cronjobs\rNAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE\rwhale-say-cronjob */1 * * * * False 0 \u0026lt;none\u0026gt; 34s\rAttendez une minute :\nkubectl get pods\rNAME READY STATUS RESTARTS AGE\rwhale-say-cronjob-1593436740-z9tf2 0/1 Completed 0 23s\rkubectl get cronjobs\rNAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE\rwhale-say-cronjob */1 * * * * False 0 48s 3m41s\rRemarquez qu\u0026rsquo;un champ important est le Last Schedule, qui nous indique quand un travail a été exécuté pour la dernière fois.\nIl est important de noter qu\u0026rsquo;un CronJob crée un travail :\nkubectl get jobs\rNAME COMPLETIONS DURATION AGE\rwhale-say-cronjob-1593436800 1/1 3s 44s\rSupprimer les ressources\nkubectl delete -f apps/kubefiles/whalesay-cronjob.yaml\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/intermediare/daemonset/","title":"Daemonset","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Un DaemonSet garantit que tous les nœuds exécutent une copie d\u0026rsquo;un Pod. Lorsque des nœuds sont ajoutés au cluster, des Pods leur sont ajoutés automatiquement. Lorsque les nœuds sont supprimés, ils ne sont pas replanifiés mais supprimés.\nAinsi, DaemonSet vous permet de déployer un Pod sur tous les nœuds.\nPreparation Si vous exécutez ce tutoriel dans Minikube, vous devez déployer un premier noeud en utilisant le driver docker :\nminikube stop\rminikube delete --all\rminikube start --driver=docker\rSi vous avez un proxy\nminikube stop\rminikube delete --all\rminikube start --docker-env HTTPS_PROXY=$HTTPS_PROXY --docker-env HTTP_PROXY=$HTTP_PROXY --docker-env=NO_PROXY=$no_proxy\rAjouter des nœuds supplémentaires pour exécuter cette partie du tutoriel. Vérifiez le nombre de nœuds que vous avez delpoyés en exécutant :\nkubectl get nodes\rSi un seul nœud est présent, vous devez créer un nouveau nœud en suivant les étapes suivantes :\nNAME STATUS ROLES AGE VERSION\rkube Ready master 54m v1.23.1\rAyant minikube installé et dans votre PATH, puis exécutez :\nminikube node add\rkubectl get nodes\rNAME STATUS ROLES AGE VERSION\rkube Ready master 54m v1.23.1\rkube-m02 Ready \u0026lt;none\u0026gt; 2m50s v1.23.1\rDaemonset Le DaemonSet est créé à l\u0026rsquo;aide de la ressource Kubernetes DaemonSet :\nvim apps/kubefiles/nginx-daemonset.yaml\rapiVersion: apps/v1\rkind: DaemonSet\rmetadata:\rname: nginx-daemonset\rlabels:\rapp: nginx-daemonset\rspec:\rselector:\rmatchLabels:\rapp: nginx-daemonset\rtemplate:\rmetadata:\rlabels:\rapp: nginx-daemonset\rspec:\rcontainers:\r- name: nginx-daemonset\rimage: nginx\rkubectl apply -f apps/kubefiles/nginx-daemonset.yaml\rkubectl get pods -o wide\rNAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES\rnginx-daemonset-jl2t5 1/1 Running 0 23s 10.244.0.2 multinode \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;\rnginx-daemonset-r64ql 1/1 Running 0 23s 10.244.1.2 multinode-m02 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;\rRemarquez qu\u0026rsquo;une instance du pod Nginx est déployée sur chaque nœud.\nSupprimer les ressources\nkubectl delete -f apps/kubefiles/quarkus-daemonset.yaml\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/intermediare/statefulsets/","title":"StatefulSets","tags":[],"description":"","content":"Prérequis  Minikube Install Driver none kubectl Install Stern Docs Release jq Install 3 terminal SSH  Preparation Si vous exécutez ce tutoriel dans Minikube, vous devez déployer un seul noeud :\nminikube stop\rminikube delete --all\rminikube start --vm-driver=none\rStatefulSet Un StatefulSet fournit une identité unique aux Pods qui le gèrent. Il peut être utilisé lorsque votre application nécessite un identifiant réseau unique ou un stockage de persistance à travers la (re)programmation des pods ou une certaine garantie sur l\u0026rsquo;ordre de déploiement et de mise à l\u0026rsquo;échelle.\nL\u0026rsquo;un des exemples les plus typiques de l\u0026rsquo;utilisation des StatefulSets est le déploiement de serveurs primaires et secondaires (par exemple, un cluster de base de données) pour lequel vous devez connaître à l\u0026rsquo;avance le nom d\u0026rsquo;hôte de chacun des serveurs pour démarrer le cluster. De même, lorsque vous effectuez une montée en charge ou une descente en charge, vous souhaitez le faire dans un ordre précis (par exemple, vous souhaitez démarrer d\u0026rsquo;abord le nœud primaire, puis le nœud secondaire).\nStatefulSet est créé en utilisant la ressource Kubernetes StatefulSet avec un service sans headless :\nvim apps/kubefiles/quarkus-statefulset.yaml\rapiVersion: apps/v1beta1\rkind: StatefulSet\rmetadata:\rname: quarkus-statefulset\rlabels:\rapp: quarkus-statefulset\rspec:\rserviceName: \u0026quot;quarkus\u0026quot; (1)\rreplicas: 2\rtemplate:\rmetadata:\rlabels:\rapp: quarkus-statefulset\rspec:\rcontainers:\r- name: quarkus-statefulset\rimage: quay.io/rhdevelopers/quarkus-demo:v1\rports:\r- containerPort: 8080\rname: web\r1- Définit le nom du statefulset utilisé comme nom d\u0026rsquo;hôte.\nLe nom d\u0026rsquo;hôte suit le même schéma dans tous les cas serviceName + un nombre commençant à 0 et il est incrémenté de un pour chaque réplique.\nEt un service headless :\n---\rapiVersion: v1\rkind: Service\rmetadata:\rname: quarkus-statefulset\rlabels:\rapp: quarkus-statefulset\rspec:\rports:\r- port: 8080\rname: web\rclusterIP: None (1)\rselector:\rapp: quarkus-statefulset\r1- Rend le service headless.\nkubectl apply -f apps/kubefiles/quarkus-statefulset.yaml\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rquarkus-statefulset-0 1/1 Running 0 12s\rRemarquez que le nom du pod est le serviceName avec un 0, car il s\u0026rsquo;agit de la première instance.\nkubectl get statefulsets\rNAME READY AGE\rquarkus-statefulset 1/1 109s\rMaintenant, on scale l\u0026rsquo;application avec 3 instances\nkubectl scale statefulset quarkus-statefulset --replicas=3\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rquarkus-statefulset-0 1/1 Running 0 95s\rquarkus-statefulset-1 1/1 Running 0 2s\rquarkus-statefulset-2 1/1 Running 0 1s\rRemarquez que le nom des Pods utilise la même nomenclature de serviceName + numéro incrémental.\nDe plus, si vous vérifiez l\u0026rsquo;ordre des événements dans le cluster Kubernetes, vous remarquerez que le nom du Pod se terminant par -1 est créé en premier, puis celui se terminant par -2.\nkubectl get events --sort-by=.metadata.creationTimestamp\r4m4s Normal SuccessfulCreate statefulset/quarkus-statefulset create Pod quarkus-statefulset-1 in StatefulSet quarkus-statefulset successful\r4m3s Normal Pulled pod/quarkus-statefulset-1 Container image \u0026quot;quay.io/rhdevelopers/quarkus-demo:v1\u0026quot; already present on machine\r4m3s Normal Scheduled pod/quarkus-statefulset-2 Successfully assigned default/quarkus-statefulset-2 to kube\r4m3s Normal Created pod/quarkus-statefulset-1 Created container quarkus-statefulset\r4m3s Normal Started pod/quarkus-statefulset-1 Started container quarkus-statefulset\r4m3s Normal SuccessfulCreate statefulset/quarkus-statefulset create Pod quarkus-statefulset-2 in StatefulSet quarkus-statefulset successful\r4m2s Normal Pulled pod/quarkus-statefulset-2 Container image \u0026quot;quay.io/rhdevelopers/quarkus-demo:v1\u0026quot; already present on machine\r4m2s Normal Created pod/quarkus-statefulset-2 Created container quarkus-statefulset\r4m2s Normal Started pod/quarkus-statefulset-2 Started container quarkus-statefulset\rEnfin, si nous réduisons à deux instances, celle qui est détruite n\u0026rsquo;est pas choisie au hasard, mais celle qui a été lancée plus tard (quarkus.statefulset-2).\nkubectl scale statefulset quarkus-statefulset --replicas=2\rkubectl get pods\rNAME READY STATUS RESTARTS AGE\rquarkus-statefulset-0 1/1 Running 0 9m22s\rquarkus-statefulset-1 1/1 Running 0 7m49s\rquarkus-statefulset-2 0/1 Terminating 0 7m48s\rSupprimer les ressources\nkubectl delete -f apps/kubefiles/quarkus-statefulset.yaml\r"},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/avance/","title":"Avancé","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/","title":"Kubernetes Tutoriel","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/kubernetes/","title":"Kubernetes","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://maxime-cls.github.io/kubernetes-tutorial/tags/","title":"Tags","tags":[],"description":"","content":""}]